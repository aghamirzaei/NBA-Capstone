{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.cross_validation import train_test_split,cross_val_predict,cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression,Lasso, Ridge\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4174, 117)\n"
     ]
    }
   ],
   "source": [
    "games_avg = pd.read_csv('../Data/CSV_files/games_avg_final02')\n",
    "del games_avg['Unnamed: 0']\n",
    "print games_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#games_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games_avg = games_avg[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 114)\n",
      "(4173, 230)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>total_score</th>\n",
       "      <th>total_line</th>\n",
       "      <th>game_line</th>\n",
       "      <th>Host_HostRank</th>\n",
       "      <th>Host_GameRank</th>\n",
       "      <th>Guest_GuestRank</th>\n",
       "      <th>Guest_GameRank</th>\n",
       "      <th>Headsup_GameRank_Season</th>\n",
       "      <th>Headsup_GameRank_All</th>\n",
       "      <th>...</th>\n",
       "      <th>loser_Oklahoma City Thunder</th>\n",
       "      <th>loser_Orlando Magic</th>\n",
       "      <th>loser_Philadelphia 76ers</th>\n",
       "      <th>loser_Phoenix Suns</th>\n",
       "      <th>loser_Portland Trail Blazers</th>\n",
       "      <th>loser_Sacramento Kings</th>\n",
       "      <th>loser_San Antonio Spurs</th>\n",
       "      <th>loser_Toronto Raptors</th>\n",
       "      <th>loser_Utah Jazz</th>\n",
       "      <th>loser_Washington Wizards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>227.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  total_score  total_line  game_line  Host_HostRank  Host_GameRank  \\\n",
       "0    2013        227.0       207.5        7.5             13             21   \n",
       "\n",
       "   Guest_GuestRank  Guest_GameRank  Headsup_GameRank_Season  \\\n",
       "0               13              22                        2   \n",
       "\n",
       "   Headsup_GameRank_All            ...             \\\n",
       "0                     2            ...              \n",
       "\n",
       "   loser_Oklahoma City Thunder  loser_Orlando Magic  loser_Philadelphia 76ers  \\\n",
       "0                          0.0                  0.0                       0.0   \n",
       "\n",
       "   loser_Phoenix Suns  loser_Portland Trail Blazers  loser_Sacramento Kings  \\\n",
       "0                 0.0                           0.0                     0.0   \n",
       "\n",
       "   loser_San Antonio Spurs  loser_Toronto Raptors  loser_Utah Jazz  \\\n",
       "0                      0.0                    0.0              0.0   \n",
       "\n",
       "   loser_Washington Wizards  \n",
       "0                       0.0  \n",
       "\n",
       "[1 rows x 230 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = games_avg[[x for x in games_avg.columns if x not in ['GameTime','GameDate','host_shortname','GameId',\n",
    "                                                                'HostScore','GuestScore','score_diff',\n",
    "                                                                'gq3','gq4','got1','got2','got3','got4',\n",
    "                                                                'hq3','hq4','hot1','hot2','hot3','hot4',\n",
    "                                                                'gq1','gq2',\n",
    "                                                                'hq1','hq2',\n",
    "                                                                #'HostName','GuestName',\n",
    "                                                                #'game_line','total_line'\n",
    "                                                                     ]]]\n",
    "\n",
    "print features.shape\n",
    "features = pd.get_dummies(features)\n",
    "print features.shape\n",
    "\n",
    "features.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Predictors and Train-Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LinearRegression to store coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20557092360896193, 0.60003444344427925, 13.485640966408118)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = features.total_score\n",
    "X = features[[x for x in features.columns if x != 'total_score']]#StandardScaler().fit_transform(features)\n",
    "\n",
    "scores = []\n",
    "predictions = []\n",
    "coefs = []\n",
    "for i in range(1000) :    \n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "\n",
    "    scores.append(lr.score(X_test,y_test))\n",
    "    predictions.append(np.mean(np.abs(lr.predict(X_test) - y_test)))\n",
    "    coefs.append(lr.coef_)\n",
    "np.mean(scores), np.std(predictions), np.mean(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find The Coefficents and Select features based on most 10% values of coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(coefs,columns=[x for x in features.columns if x != 'total_score'])\n",
    "\n",
    "coef_df = coef_df.applymap(lambda x: 1 if x >= 0 else 0)\n",
    "coef_sum = coef_df.sum(0)\n",
    "coef_effect = pd.DataFrame(coef_sum,columns=['count_positive']).reset_index()\n",
    "coef_list = coef_effect[(coef_effect.count_positive > 900) | (coef_effect.count_positive <100)]['index']\n",
    "#games_avg[coef_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Run The Linear Regression with Most Important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26194506937645429, 0.017121502836787539, 12.967638458471161)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = games_avg[coef_list]\n",
    "\n",
    "scores = []\n",
    "predictions = []\n",
    "coefs = []\n",
    "for i in range(1000) :    \n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)\n",
    "    lr = LinearRegression()\n",
    "    #lr = Ridge()\n",
    "    lr.fit(X_train,y_train)\n",
    "\n",
    "    scores.append(lr.score(X_test,y_test))\n",
    "    predictions.append(np.mean(np.abs(lr.predict(X_test) - y_test)))\n",
    "    coefs.append(lr.coef_)\n",
    "np.mean(scores), np.std(scores), np.mean(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gread Search for Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Previous Seasons Data to predict the last Season With Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicts = []\n",
    "scores = []\n",
    "\n",
    "coef_list_final = list(coef_list)\n",
    "coef_list_final.append('total_score')\n",
    "#list(coef_list)\n",
    "\n",
    "features_train = features[features.Season.isin([2013,2014,2015,2016])]#[coef_list_final]\n",
    "features_test = features[features.Season.isin([2017])]#[coef_list_final]\n",
    "\n",
    "X_train = features_train[[x for x in features_train.columns if x != 'total_score']]\n",
    "y_train = features_train.total_score\n",
    "X_test = features_test[[x for x in features_test.columns if x != 'total_score']]\n",
    "y_test = features_test.total_score\n",
    "\n",
    "model = RandomForestRegressor(min_samples_split=16,max_features=None,max_depth=None,n_estimators=1500)\n",
    "#model = Ridge(alpha=1980)\n",
    "#model = RandomForestRegressor(min_samples_split=16,max_features=25,max_depth=16,n_estimators=1500)\n",
    "#model = GradientBoostingRegressor(n_estimators=500,min_samples_split=16,learning_rate=0.01)\n",
    "#model = AdaBoostRegressor()\n",
    "#model = LinearRegression()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "predicts = model.predict(X_test)\n",
    "scores = model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (3768, 229)\n",
      "Test Data Shape: (405, 229) Whole Data Shape (4173, 230)\n",
      "---------------------------------\n",
      "Regression Model score: 0.165478430941\n",
      "Mean Absolute Error: 13.1895953102\n",
      "Bet Line Mean Absolute Error of All Games: 12.9148148148\n",
      "----------------------------------------\n",
      "Baseline:\n",
      "Total Count/Percent Of Actual Over:(Base Line) 193 -- 47.6543209877\n",
      "Total Count/Percent Of Actual Under:(Base Line) 206 -- 50.8641975309\n",
      "Total Count/Percent Of Actual Tie:(Base Line) 6 -- 1.48148148148\n",
      "----------------------------------------\n",
      "Confussion Metrix:\n",
      "True Over: 54 False Over: 44\n",
      "False Under: 144 True Under: 163\n",
      "\n",
      "Total Predicted Over: 98 -- Over Accuracy: 55.1020408163\n",
      "Total Predicted Under: 307 -- Under Accuracy: 53.0944625407\n",
      "****************************************\n",
      "****************************************\n",
      "Number and percent of games that i win:: 217  --  53.5802469136\n",
      "Number and percent of games that i lose: 182  --  44.9382716049\n",
      "Number and percent of games that i draw: 6  --  1.48148148148\n",
      "percent of pure win with bet on over/under: 4.14814814815 %\n",
      "****************************************\n",
      "****************************************\n",
      "\n",
      "% of win, When i predict bad: 37.9310344828\n",
      "Mean Residials : 22.6202595986\n",
      "Bet Mean Residials : 21.5114942529\n",
      "number of bad predicted games: 174\n",
      "---------------------------------\n",
      "% of win, When i predict good: 65.367965368\n",
      "Mean Residials : 6.085978054\n",
      "Bet Mean Residials : 6.43939393939\n",
      "number of good predicted games: 231\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "% of win, When i predict close to the line: 52.6946107784\n",
      "Mean Residials : 13.4604178436\n",
      "Bet Mean Residials : 13.5988023952\n",
      "number of bad predicted games: 167\n",
      "----------------------------------\n",
      "% of win, When i predict far from the line: 50.5405405405\n",
      "Mean Residials : 14.3420731007\n",
      "Bet Mean Residials : 13.8243243243\n",
      "number of good predicted games: 370\n"
     ]
    }
   ],
   "source": [
    "mydata = pd.DataFrame(X_test, columns=features.columns)\n",
    "mydata['y_true'] = y_test\n",
    "mydata['y_hat'] = predicts\n",
    "\n",
    "team_names = games_avg[['HostName','GuestName']] #,'HostScore','GuestScore'\n",
    "mydata = mydata.merge(team_names,left_index=True,right_index=True,suffixes=('',''))\n",
    "\n",
    "mydata['myerror'] = np.abs(mydata.y_hat - mydata.y_true)\n",
    "mydata['beterror'] = np.abs(mydata.total_line - mydata.y_true)\n",
    "mydata['errordiff'] = np.abs(mydata.y_hat - mydata.total_line)\n",
    "\n",
    "def confusion_metrix(row) :\n",
    "    \n",
    "    if row['y_hat'] >= row['total_line'] :\n",
    "        if row['y_true'] > row['total_line'] :\n",
    "            row['true_over']  = 1\n",
    "            row['false_over'] = 0\n",
    "            row['true_under'] = 0\n",
    "            row['false_under']= 0\n",
    "        else :\n",
    "            row['true_over']  = 0\n",
    "            row['false_over'] = 1\n",
    "            row['true_under'] = 0\n",
    "            row['false_under']= 0\n",
    "\n",
    "    if row['y_hat'] < row['total_line'] :\n",
    "        if row['y_true'] < row['total_line'] :\n",
    "            row['true_over']  = 0\n",
    "            row['false_over'] = 0\n",
    "            row['true_under'] = 1\n",
    "            row['false_under']= 0\n",
    "        else :\n",
    "            row['true_over']  = 0\n",
    "            row['false_over'] = 0\n",
    "            row['true_under'] = 0\n",
    "            row['false_under']= 1    \n",
    "    return row\n",
    "\n",
    "mydata = mydata.apply(confusion_metrix,axis=1)\n",
    "        \n",
    "def ifIWon(row) :\n",
    "    if (row['y_true'] > row['total_line']) & (row['y_hat'] > row['total_line']) :\n",
    "        row['win_total_line'] = 1\n",
    "    elif (row['y_true'] < row['total_line']) & (row['y_hat'] < row['total_line']) :\n",
    "        row['win_total_line'] = 1\n",
    "    elif row['y_true'] == row['total_line'] :\n",
    "        row['win_total_line'] = 0\n",
    "    else :\n",
    "        row['win_total_line'] = -1\n",
    "    return row\n",
    "\n",
    "mydata = mydata.apply(ifIWon, axis = 1)\n",
    "\n",
    "def baseline(row) :\n",
    "    if (row['y_true'] > row['total_line'])  :\n",
    "        row['over_under'] = 1\n",
    "    elif  (row['y_true'] == row['total_line']):\n",
    "        row['over_under'] = 0\n",
    "    else :\n",
    "        row['over_under'] = -1\n",
    "    return row\n",
    "\n",
    "mydata = mydata.apply(baseline, axis = 1)\n",
    "\n",
    "def my_over_under(row) :\n",
    "    if (row['y_hat'] >= row['total_line'])  :\n",
    "        row['my_over_under'] = 1\n",
    "    else :\n",
    "        row['my_over_under'] = 0\n",
    "    return row\n",
    "\n",
    "mydata = mydata.apply(my_over_under, axis = 1)\n",
    "\n",
    "\n",
    "errordata = mydata[['Season','GuestName','HostName','y_true','total_line',\n",
    "                    'y_hat','myerror','beterror','errordiff','over_under','my_over_under',\n",
    "                    'win_total_line','true_over','true_under','false_over','false_under',\n",
    "                    'Host_HostRank','Host_GameRank','Guest_GuestRank','Guest_GameRank',\n",
    "                    'game_line','Headsup_GameRank_Season','Headsup_GameRank_All',\n",
    "                    'Host_LastGameDiff','Guest_LastGameDiff','host_win_count','host_lose_count',\n",
    "                    'guest_win_count','guest_lose_count','game_behind','host_strike','guest_strike',\n",
    "                    'host_place_streak','guest_place_streak'\n",
    "                   ]]\n",
    "\n",
    "\n",
    "wheniwin = errordata[errordata.win_total_line == 1]\n",
    "wheniloose = errordata[errordata.win_total_line == -1]\n",
    "whenidraw = errordata[errordata.win_total_line == 0]\n",
    "\n",
    "\n",
    "error_margin = 13\n",
    "differrormargin = 2\n",
    "\n",
    "bigesterrors = errordata[errordata.myerror > error_margin]\n",
    "smallestsrrors = errordata[errordata.myerror <=error_margin]\n",
    "closesterrors = errordata[errordata.errordiff <=differrormargin]\n",
    "faresterrors = errordata[errordata.myerror > differrormargin]\n",
    "\n",
    "print 'Train Data Shape:',X_train.shape\n",
    "print 'Test Data Shape:',X_test.shape,\n",
    "print 'Whole Data Shape' ,features.shape\n",
    "print '---------------------------------'\n",
    "print 'Regression Model score:', scores\n",
    "print 'Mean Absolute Error:', errordata.myerror.mean()\n",
    "print 'Bet Line Mean Absolute Error of All Games:', errordata.beterror.mean()\n",
    "print '----------------------------------------'\n",
    "print 'Baseline:'\n",
    "print 'Total Count/Percent Of Actual Over:(Base Line)',mydata.over_under[mydata.over_under == 1].count(),'--',100.*mydata.over_under[mydata.over_under == 1].count()/mydata.over_under.count()\n",
    "print 'Total Count/Percent Of Actual Under:(Base Line)',mydata.over_under[mydata.over_under == -1].count(),'--',100.*mydata.over_under[mydata.over_under == -1].count()/mydata.over_under.count()\n",
    "print 'Total Count/Percent Of Actual Tie:(Base Line)',mydata.over_under[mydata.over_under == 0].count(),'--',100.*mydata.over_under[mydata.over_under == 0].count()/mydata.over_under.count()\n",
    "print '----------------------------------------'\n",
    "print 'Confussion Metrix:'\n",
    "print 'True Over:',mydata.true_over.sum(),'False Over:',mydata.false_over.sum()\n",
    "print 'False Under:',mydata.false_under.sum(),'True Under:',mydata.true_under.sum()\n",
    "print \n",
    "print 'Total Predicted Over:',mydata.true_over.sum()+mydata.false_over.sum(),\n",
    "print '-- Over Accuracy:',100.*mydata.true_over.sum()/(mydata.true_over.sum() + mydata.false_over.sum())\n",
    "print 'Total Predicted Under:',mydata.true_under.sum()+mydata.false_under.sum(),\n",
    "print '-- Under Accuracy:',100.*mydata.true_under.sum()/(mydata.true_under.sum() + mydata.false_under.sum())\n",
    "print '****************************************'\n",
    "print '****************************************'\n",
    "print 'Number and percent of games that i win::',errordata[errordata.win_total_line == 1]['win_total_line'].count(),' -- ',\n",
    "print 100.0*errordata[errordata.win_total_line == 1]['win_total_line'].count() /errordata.win_total_line.count() \n",
    "\n",
    "print 'Number and percent of games that i lose:',errordata[errordata.win_total_line == -1]['win_total_line'].count(),' -- ',\n",
    "print 100.0*errordata[errordata.win_total_line == -1]['win_total_line'].count() /errordata.win_total_line.count() \n",
    "\n",
    "print 'Number and percent of games that i draw:',errordata[errordata.win_total_line == 0]['win_total_line'].count(),' -- ',\n",
    "print 100.0*errordata[errordata.win_total_line == 0]['win_total_line'].count() /errordata.win_total_line.count() \n",
    "\n",
    "print 'percent of pure win with bet on over/under:',100*(wheniwin.shape[0] - 1.1*wheniloose.shape[0])/X_test.shape[0],'%'\n",
    "print '****************************************'\n",
    "print '****************************************'\n",
    "print\n",
    "print '% of win, When i predict bad:',100.0*bigesterrors[bigesterrors.win_total_line == 1]['win_total_line'].sum() /bigesterrors.win_total_line.count() \n",
    "print 'Mean Residials :',bigesterrors.myerror.mean()\n",
    "print 'Bet Mean Residials :',bigesterrors.beterror.mean()\n",
    "print 'number of bad predicted games:',bigesterrors.shape[0]\n",
    "print '---------------------------------'\n",
    "print '% of win, When i predict good:',100.0*smallestsrrors[smallestsrrors.win_total_line == 1]['win_total_line'].sum() /smallestsrrors.win_total_line.count() \n",
    "print 'Mean Residials :',smallestsrrors.myerror.mean()\n",
    "print 'Bet Mean Residials :',smallestsrrors.beterror.mean() \n",
    "print 'number of good predicted games:', smallestsrrors.shape[0] \n",
    "print '---------------------------------'\n",
    "print '---------------------------------'\n",
    "print '% of win, When i predict close to the line:',100.0*closesterrors[closesterrors.win_total_line == 1]['win_total_line'].sum() /closesterrors.win_total_line.count() \n",
    "print 'Mean Residials :',closesterrors.myerror.mean()\n",
    "print 'Bet Mean Residials :',closesterrors.beterror.mean()\n",
    "print 'number of bad predicted games:',closesterrors.shape[0]\n",
    "print '----------------------------------'\n",
    "print '% of win, When i predict far from the line:',100.0*faresterrors[faresterrors.win_total_line == 1]['win_total_line'].sum() /faresterrors.win_total_line.count() \n",
    "print 'Mean Residials :',faresterrors.myerror.mean()\n",
    "print 'Bet Mean Residials :',faresterrors.beterror.mean() \n",
    "print 'number of good predicted games:', faresterrors.shape[0] \n",
    "\n",
    "errordata.to_csv('../Data/CSV_files/error_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to Find the Games that i'm so off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1429-d84ca25612f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtemp_X_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_hat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtemp_X_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_true'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtemp_X_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'myerror'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_X_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_hat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtemp_X_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtemp_X_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_bad'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_X_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyerror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/behdad/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2357\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/behdad/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2423\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/behdad/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2577\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2578\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2579\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/behdad/anaconda/envs/dsi/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "temp_X_test = X_test\n",
    "temp_X_test['y_hat'] = predicts\n",
    "temp_X_test['y_true'] = y_test\n",
    "temp_X_test['myerror'] = np.abs(temp_X_test['y_hat'] - temp_X_test['y_true'])\n",
    "temp_X_test['is_bad'] = temp_X_test.myerror.apply(lambda x : 1 if x > 15 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X_train = X_test\n",
    "new_y_train = temp_X_test.is_bad\n",
    "new_X_test = X_train\n",
    "#new_y_test = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 985 entries, 2783 to 3767\n",
      "Columns: 233 entries, Season to myerror\n",
      "dtypes: float64(217), int64(16)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2783 entries, 0 to 2782\n",
      "Columns: 229 entries, Season to loser_Washington Wizards\n",
      "dtypes: float64(214), int64(15)\n",
      "memory usage: 4.9 MB\n"
     ]
    }
   ],
   "source": [
    "new_X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(985, 233) (985, 233) (985,) (2783, 229)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape,new_X_train.shape, new_y_train.shape,new_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROAD MAP\n",
    "\n",
    "### Feature Engineering \n",
    "- Create differenet Avg columns\n",
    "- Create Agg columns for heads-up matches\n",
    "- Create features for distance traveled/time zone change\n",
    "- Add Game Time to recovery time\n",
    "\n",
    "Test which average lengths work best in the model. Try out exponentially weighted moving average. Test different decay strengths. Maybe write your own \"grid search\" over decay strengths: for a decay automatically make the averaged variables and then build, test a model. Record the performance of each one.\n",
    "\n",
    "Put host and opponent columns back in to test with random forest (interactions may be important, even if main effects were not). You can check/validate by looking at feature importances.\n",
    "\n",
    "\n",
    "### Model Improvement\n",
    "- Create model for predicting high risk games based on Mean Absolute Error\n",
    "\n",
    "\n",
    "\n",
    "### Model Execution And Prediction \n",
    "- Develop Application to scrape last day match/bet results\n",
    "- Develop Application to input next game and give back the prediction \n",
    "\n",
    "https://github.com/ipython/ipywidgets\n",
    "https://demo.bokehplots.com/\n",
    "\n",
    "\n",
    "### Leaning Porpuses\n",
    "- Put my data and model in AWS\n",
    "\n",
    "\n",
    "### Questions\n",
    "- Which Fundumental Concepts could be usefull for my model improvment? \n",
    "- - PCA\n",
    "- - Bootstapping\n",
    "- - Bagging & Boosting\n",
    "- - T-Test\n",
    "- - Bayesian Statistics\n",
    "- - ???\n",
    "- Do you want to invest on my model? :-D\n",
    "\n",
    "\n",
    "RDS for database or EC2,doccer in easier\n",
    "\n",
    "EC2 instance, lubanto in the first 4 amazon images, \n",
    "\n",
    "EMR cluster, in spark \n",
    "upload my csv to master, zipplin or pyspark\n",
    "SCP utility,takes and source destination\n",
    "spark.read\n",
    "\n",
    "## OLD Kiefer Notes :\n",
    "Training data:\n",
    "\n",
    "Currently:\n",
    "y_true = total score of the game\n",
    "your model is predicting the total score\n",
    "\n",
    "You can also have a second target:\n",
    "y_diff = error_diff \n",
    "Predict y_diff from your features - the same features you used to predict y_true\n",
    "Split training data into 2 halves, make error_diff for each with model built on the other\n",
    "\n",
    "Also try random forest\n",
    "\n",
    "parameters to gridsearch for RandomForestRegressor:\n",
    "\n",
    "```python\n",
    "params = {\n",
    "    'n_estimators':[1000],\n",
    "    'criterion':['mae'],\n",
    "    'max_depth':[2,3,5,7,None],\n",
    "    'min_samples_split':[2,4,8,16,32,64,128],\n",
    "    'max_features':[None, 'sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed: 10.0min\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed: 134.6min\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 152.8min finished\n"
     ]
    }
   ],
   "source": [
    "rf_predicts = []\n",
    "rf_scores = []\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[1500,1000],\n",
    "    'criterion':['mse'],\n",
    "    'max_depth':[2,16,None],\n",
    "    'min_samples_split':[2,8,16],\n",
    "    'max_features':[None, 'sqrt',25]\n",
    "    }\n",
    "\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "estimator = GridSearchCV(rf, params, cv= 4, verbose= 1)\n",
    "\n",
    "estimator.fit(X_train,y_train)\n",
    "\n",
    "rf_predicts = estimator.predict(X_test)\n",
    "rf_scores = estimator.score(X_test,y_test)\n",
    "\n",
    "print rf_scores, np.mean(rf_scores)\n",
    "print estimator.best_params_\n",
    "print np.mean(np.abs(estimator.predict(X_test) - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/behdad/anaconda/envs/dsi/lib/python2.7/site-packages/sklearn/cross_validation.py:1531: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/behdad/anaconda/envs/dsi/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:454: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/behdad/anaconda/envs/dsi/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646942785319\n",
      "8.55690771843\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha' : np.arange(0, 1, 0.01)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "estimator = GridSearchCV(lasso,param_grid=params,cv=10)\n",
    "estimator.fit(X_train,y_train)\n",
    "\n",
    "predictions = estimator.predict(X_test)\n",
    "\n",
    "print estimator.score(X_test,y_test)\n",
    "print np.mean(np.abs(predictions - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854026618022\n",
      "8.54883865101\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha' : np.arange(200, 10000, 50)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "estimator = GridSearchCV(ridge,param_grid=params,cv=5)\n",
    "estimator.fit(X_train,y_train)\n",
    "\n",
    "predictions = estimator.predict(X_test)\n",
    "\n",
    "print estimator.score(X_test,y_test)\n",
    "print np.mean(np.abs(predictions - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 200}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554890215212\n",
      "14.8290748899\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "dtr.fit(X_train,y_train)\n",
    "\n",
    "predictions = dtr.predict(X_test)\n",
    "\n",
    "print dtr.score(X_test,y_test)\n",
    "print np.mean(np.abs(predictions - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.214871131454\n",
      "13.899822307\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "\n",
    "svr.fit(X_train,y_train)\n",
    "\n",
    "predictions = svr.predict(X_test)\n",
    "\n",
    "print svr.score(X_test,y_test)\n",
    "print np.mean(np.abs(predictions - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games_pca = PCA()\n",
    "games_pca.fit(X)\n",
    "games_pcs = games_pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtIAAAIiCAYAAADl+C+zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e167a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(range(1, X.shape[1]+1), games_pca.explained_variance_ratio_, lw=2)\n",
    "ax.scatter(range(1, X.shape[1]+1), games_pca.explained_variance_ratio_, s=100)\n",
    "ax.set_title('explained variance of components')\n",
    "ax.set_xlabel('principal component')\n",
    "ax.set_ylabel('explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.53257204e-02,   1.08622119e-01,   1.08891573e-01, ...,\n",
       "         -9.91182918e-04,  -2.81420112e-03,  -4.10096432e-03],\n",
       "       [ -5.11770633e-02,   1.26781110e-02,  -1.09319381e-02, ...,\n",
       "         -1.38865297e-02,   4.92336255e-02,   9.83173486e-03],\n",
       "       [  1.73763427e-02,  -2.06112755e-02,  -3.17114763e-02, ...,\n",
       "         -5.11786209e-02,  -5.28372291e-03,   5.87892375e-02],\n",
       "       ..., \n",
       "       [ -1.11287417e-13,  -9.24534955e-14,  -3.32820996e-14, ...,\n",
       "          5.98222469e-06,   5.68012485e-06,   5.95771935e-06],\n",
       "       [ -2.24448110e-16,  -7.20267868e-17,  -1.41490210e-16, ...,\n",
       "          1.46840896e-01,   1.39425488e-01,   1.46239378e-01],\n",
       "       [  0.00000000e+00,   3.97465975e-17,   1.41487571e-17, ...,\n",
       "          1.12711569e-01,   1.07019678e-01,   1.12249857e-01]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3439, 30)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_pcs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3439, 143)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games_pcs = pd.DataFrame(games_pcs)\n",
    "games_pcs = games_pcs.iloc[:,:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.982755</td>\n",
       "      <td>-4.115200</td>\n",
       "      <td>1.406928</td>\n",
       "      <td>-3.757984</td>\n",
       "      <td>3.656259</td>\n",
       "      <td>1.613922</td>\n",
       "      <td>-1.890569</td>\n",
       "      <td>-2.622225</td>\n",
       "      <td>-2.661984</td>\n",
       "      <td>2.518709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.738718</td>\n",
       "      <td>-0.023524</td>\n",
       "      <td>-0.969870</td>\n",
       "      <td>-0.562183</td>\n",
       "      <td>-1.216451</td>\n",
       "      <td>1.134578</td>\n",
       "      <td>-0.182661</td>\n",
       "      <td>-2.046463</td>\n",
       "      <td>-1.864370</td>\n",
       "      <td>0.570880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.607682</td>\n",
       "      <td>7.496757</td>\n",
       "      <td>3.454382</td>\n",
       "      <td>5.037950</td>\n",
       "      <td>-0.579141</td>\n",
       "      <td>-0.176741</td>\n",
       "      <td>0.166539</td>\n",
       "      <td>0.840192</td>\n",
       "      <td>0.313012</td>\n",
       "      <td>1.047595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918762</td>\n",
       "      <td>-0.638830</td>\n",
       "      <td>1.385301</td>\n",
       "      <td>-0.052956</td>\n",
       "      <td>-0.145171</td>\n",
       "      <td>1.455080</td>\n",
       "      <td>1.075812</td>\n",
       "      <td>0.482158</td>\n",
       "      <td>1.494449</td>\n",
       "      <td>-1.311899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.997884</td>\n",
       "      <td>-3.165365</td>\n",
       "      <td>-4.122333</td>\n",
       "      <td>-1.276138</td>\n",
       "      <td>0.118351</td>\n",
       "      <td>-2.938084</td>\n",
       "      <td>2.389109</td>\n",
       "      <td>-0.843803</td>\n",
       "      <td>-1.732838</td>\n",
       "      <td>-4.986368</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.204822</td>\n",
       "      <td>0.755812</td>\n",
       "      <td>-0.722123</td>\n",
       "      <td>-1.416533</td>\n",
       "      <td>0.679098</td>\n",
       "      <td>1.199353</td>\n",
       "      <td>1.478558</td>\n",
       "      <td>-0.986917</td>\n",
       "      <td>-0.521556</td>\n",
       "      <td>-0.736711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.748678</td>\n",
       "      <td>-1.478169</td>\n",
       "      <td>-0.594992</td>\n",
       "      <td>-4.158985</td>\n",
       "      <td>2.174499</td>\n",
       "      <td>-0.259768</td>\n",
       "      <td>2.037785</td>\n",
       "      <td>0.962816</td>\n",
       "      <td>-0.378658</td>\n",
       "      <td>1.723109</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.596054</td>\n",
       "      <td>0.155321</td>\n",
       "      <td>-1.061750</td>\n",
       "      <td>2.784604</td>\n",
       "      <td>-2.075540</td>\n",
       "      <td>0.969271</td>\n",
       "      <td>-1.007516</td>\n",
       "      <td>-1.041927</td>\n",
       "      <td>-0.408836</td>\n",
       "      <td>-0.179374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.887310</td>\n",
       "      <td>-5.232141</td>\n",
       "      <td>2.010836</td>\n",
       "      <td>1.554207</td>\n",
       "      <td>-0.550797</td>\n",
       "      <td>3.529540</td>\n",
       "      <td>5.317237</td>\n",
       "      <td>0.790587</td>\n",
       "      <td>-0.670597</td>\n",
       "      <td>-2.453734</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.607736</td>\n",
       "      <td>0.351768</td>\n",
       "      <td>0.106923</td>\n",
       "      <td>-2.728456</td>\n",
       "      <td>-0.613580</td>\n",
       "      <td>-0.222306</td>\n",
       "      <td>1.070596</td>\n",
       "      <td>0.956270</td>\n",
       "      <td>-0.864357</td>\n",
       "      <td>-0.182315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.572635</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>2.006660</td>\n",
       "      <td>-1.515516</td>\n",
       "      <td>-1.117444</td>\n",
       "      <td>-2.525403</td>\n",
       "      <td>6.439270</td>\n",
       "      <td>0.794542</td>\n",
       "      <td>1.419729</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.113163</td>\n",
       "      <td>-3.563197</td>\n",
       "      <td>-0.602929</td>\n",
       "      <td>-1.062612</td>\n",
       "      <td>-1.118831</td>\n",
       "      <td>-0.488971</td>\n",
       "      <td>0.149708</td>\n",
       "      <td>0.157637</td>\n",
       "      <td>-0.749770</td>\n",
       "      <td>-1.297730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.259470</td>\n",
       "      <td>0.098404</td>\n",
       "      <td>-0.458336</td>\n",
       "      <td>1.818204</td>\n",
       "      <td>-1.858724</td>\n",
       "      <td>-3.302179</td>\n",
       "      <td>-0.893786</td>\n",
       "      <td>-0.698713</td>\n",
       "      <td>-3.780284</td>\n",
       "      <td>2.449144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.878282</td>\n",
       "      <td>0.947494</td>\n",
       "      <td>-1.596418</td>\n",
       "      <td>1.719465</td>\n",
       "      <td>0.658379</td>\n",
       "      <td>-0.670800</td>\n",
       "      <td>-2.189380</td>\n",
       "      <td>0.263769</td>\n",
       "      <td>1.024148</td>\n",
       "      <td>-0.888278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.839558</td>\n",
       "      <td>3.130066</td>\n",
       "      <td>0.852576</td>\n",
       "      <td>0.694067</td>\n",
       "      <td>-3.162966</td>\n",
       "      <td>-4.763087</td>\n",
       "      <td>1.578844</td>\n",
       "      <td>0.565021</td>\n",
       "      <td>3.119084</td>\n",
       "      <td>-4.506019</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.034292</td>\n",
       "      <td>-0.095932</td>\n",
       "      <td>-2.281433</td>\n",
       "      <td>1.199133</td>\n",
       "      <td>-0.307719</td>\n",
       "      <td>-0.223515</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-0.330136</td>\n",
       "      <td>-1.119633</td>\n",
       "      <td>-1.172055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.849369</td>\n",
       "      <td>-0.710844</td>\n",
       "      <td>-0.011611</td>\n",
       "      <td>2.792113</td>\n",
       "      <td>5.369946</td>\n",
       "      <td>2.842351</td>\n",
       "      <td>2.248036</td>\n",
       "      <td>3.087862</td>\n",
       "      <td>2.111505</td>\n",
       "      <td>-4.127600</td>\n",
       "      <td>...</td>\n",
       "      <td>2.397921</td>\n",
       "      <td>0.228280</td>\n",
       "      <td>-0.146146</td>\n",
       "      <td>0.482149</td>\n",
       "      <td>0.261895</td>\n",
       "      <td>1.823439</td>\n",
       "      <td>-0.922943</td>\n",
       "      <td>1.771317</td>\n",
       "      <td>-0.703432</td>\n",
       "      <td>-0.097629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.319738</td>\n",
       "      <td>2.343567</td>\n",
       "      <td>1.054355</td>\n",
       "      <td>5.043071</td>\n",
       "      <td>1.911188</td>\n",
       "      <td>-6.283395</td>\n",
       "      <td>-0.080140</td>\n",
       "      <td>1.584919</td>\n",
       "      <td>4.934165</td>\n",
       "      <td>3.112176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760758</td>\n",
       "      <td>0.586755</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.411074</td>\n",
       "      <td>1.018920</td>\n",
       "      <td>-1.094989</td>\n",
       "      <td>0.500371</td>\n",
       "      <td>-0.442784</td>\n",
       "      <td>0.931434</td>\n",
       "      <td>-1.870566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.421684</td>\n",
       "      <td>5.522900</td>\n",
       "      <td>-3.426086</td>\n",
       "      <td>-5.876746</td>\n",
       "      <td>3.418981</td>\n",
       "      <td>-9.293457</td>\n",
       "      <td>-4.082693</td>\n",
       "      <td>-1.709574</td>\n",
       "      <td>-0.736761</td>\n",
       "      <td>2.179015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514239</td>\n",
       "      <td>-2.182177</td>\n",
       "      <td>1.086405</td>\n",
       "      <td>0.902301</td>\n",
       "      <td>-0.406464</td>\n",
       "      <td>0.282490</td>\n",
       "      <td>-0.333232</td>\n",
       "      <td>1.568376</td>\n",
       "      <td>2.374852</td>\n",
       "      <td>1.739884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.073767</td>\n",
       "      <td>-1.200186</td>\n",
       "      <td>-2.275805</td>\n",
       "      <td>-0.260582</td>\n",
       "      <td>-3.027405</td>\n",
       "      <td>-2.950029</td>\n",
       "      <td>0.180111</td>\n",
       "      <td>-2.948363</td>\n",
       "      <td>0.541833</td>\n",
       "      <td>1.694014</td>\n",
       "      <td>...</td>\n",
       "      <td>1.483620</td>\n",
       "      <td>-0.727931</td>\n",
       "      <td>0.340058</td>\n",
       "      <td>0.912624</td>\n",
       "      <td>-3.061016</td>\n",
       "      <td>-2.632392</td>\n",
       "      <td>0.224033</td>\n",
       "      <td>-0.654526</td>\n",
       "      <td>-0.998330</td>\n",
       "      <td>-1.006495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.991178</td>\n",
       "      <td>1.183007</td>\n",
       "      <td>4.047436</td>\n",
       "      <td>1.011372</td>\n",
       "      <td>-0.554906</td>\n",
       "      <td>-2.954260</td>\n",
       "      <td>0.918956</td>\n",
       "      <td>2.620994</td>\n",
       "      <td>2.008918</td>\n",
       "      <td>-2.200251</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.815877</td>\n",
       "      <td>-2.802456</td>\n",
       "      <td>-1.800421</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>-0.627934</td>\n",
       "      <td>-0.522232</td>\n",
       "      <td>-0.016081</td>\n",
       "      <td>1.709427</td>\n",
       "      <td>-0.316162</td>\n",
       "      <td>-0.527561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.364150</td>\n",
       "      <td>2.678412</td>\n",
       "      <td>-0.862547</td>\n",
       "      <td>-4.093276</td>\n",
       "      <td>-3.437406</td>\n",
       "      <td>-1.767157</td>\n",
       "      <td>1.156182</td>\n",
       "      <td>-3.130842</td>\n",
       "      <td>-2.050123</td>\n",
       "      <td>1.328194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430343</td>\n",
       "      <td>2.738608</td>\n",
       "      <td>0.924460</td>\n",
       "      <td>0.234684</td>\n",
       "      <td>1.708144</td>\n",
       "      <td>0.750217</td>\n",
       "      <td>1.033675</td>\n",
       "      <td>0.581809</td>\n",
       "      <td>0.464666</td>\n",
       "      <td>-1.744320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.521345</td>\n",
       "      <td>0.174426</td>\n",
       "      <td>2.732667</td>\n",
       "      <td>2.109188</td>\n",
       "      <td>0.179922</td>\n",
       "      <td>-1.246286</td>\n",
       "      <td>-0.219240</td>\n",
       "      <td>0.980361</td>\n",
       "      <td>1.631902</td>\n",
       "      <td>-0.163416</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.962625</td>\n",
       "      <td>-0.704194</td>\n",
       "      <td>-1.626188</td>\n",
       "      <td>-0.203017</td>\n",
       "      <td>0.792994</td>\n",
       "      <td>2.934628</td>\n",
       "      <td>0.772448</td>\n",
       "      <td>1.792112</td>\n",
       "      <td>2.018564</td>\n",
       "      <td>0.951161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.737193</td>\n",
       "      <td>1.076513</td>\n",
       "      <td>2.423806</td>\n",
       "      <td>6.504006</td>\n",
       "      <td>4.087897</td>\n",
       "      <td>-2.799494</td>\n",
       "      <td>-0.608417</td>\n",
       "      <td>-1.382329</td>\n",
       "      <td>0.298526</td>\n",
       "      <td>-0.555837</td>\n",
       "      <td>...</td>\n",
       "      <td>2.575143</td>\n",
       "      <td>1.405744</td>\n",
       "      <td>2.100426</td>\n",
       "      <td>1.144254</td>\n",
       "      <td>2.194890</td>\n",
       "      <td>0.333516</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>-1.330217</td>\n",
       "      <td>-1.176694</td>\n",
       "      <td>-0.657595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.406272</td>\n",
       "      <td>1.945512</td>\n",
       "      <td>-1.325678</td>\n",
       "      <td>1.700711</td>\n",
       "      <td>-1.715407</td>\n",
       "      <td>-2.369002</td>\n",
       "      <td>2.310580</td>\n",
       "      <td>0.173924</td>\n",
       "      <td>-1.862845</td>\n",
       "      <td>0.439541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285021</td>\n",
       "      <td>0.292112</td>\n",
       "      <td>-2.731116</td>\n",
       "      <td>0.098853</td>\n",
       "      <td>-0.615002</td>\n",
       "      <td>-1.209755</td>\n",
       "      <td>-0.771788</td>\n",
       "      <td>-0.781801</td>\n",
       "      <td>0.699097</td>\n",
       "      <td>-1.571110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.252831</td>\n",
       "      <td>0.442091</td>\n",
       "      <td>1.580202</td>\n",
       "      <td>0.383030</td>\n",
       "      <td>-0.848218</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.944963</td>\n",
       "      <td>-1.410303</td>\n",
       "      <td>2.463184</td>\n",
       "      <td>-0.229165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.359755</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-2.600352</td>\n",
       "      <td>-1.113253</td>\n",
       "      <td>-1.866813</td>\n",
       "      <td>0.915951</td>\n",
       "      <td>-0.334732</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>1.400462</td>\n",
       "      <td>-1.802234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.551387</td>\n",
       "      <td>-3.945093</td>\n",
       "      <td>2.828089</td>\n",
       "      <td>0.274768</td>\n",
       "      <td>-2.269408</td>\n",
       "      <td>-3.895442</td>\n",
       "      <td>1.719025</td>\n",
       "      <td>0.914404</td>\n",
       "      <td>-0.806722</td>\n",
       "      <td>-3.125392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180487</td>\n",
       "      <td>1.046214</td>\n",
       "      <td>-3.115611</td>\n",
       "      <td>1.606211</td>\n",
       "      <td>1.432894</td>\n",
       "      <td>-0.732741</td>\n",
       "      <td>-0.827905</td>\n",
       "      <td>2.213189</td>\n",
       "      <td>0.715115</td>\n",
       "      <td>-1.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.017185</td>\n",
       "      <td>-3.163206</td>\n",
       "      <td>-1.029822</td>\n",
       "      <td>2.439137</td>\n",
       "      <td>1.135837</td>\n",
       "      <td>-3.118376</td>\n",
       "      <td>1.950225</td>\n",
       "      <td>0.166213</td>\n",
       "      <td>0.533472</td>\n",
       "      <td>-1.182007</td>\n",
       "      <td>...</td>\n",
       "      <td>2.471908</td>\n",
       "      <td>2.681405</td>\n",
       "      <td>0.156003</td>\n",
       "      <td>1.635769</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>-1.486807</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.240987</td>\n",
       "      <td>0.348562</td>\n",
       "      <td>0.926298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.407621</td>\n",
       "      <td>-5.456649</td>\n",
       "      <td>2.148830</td>\n",
       "      <td>-3.605895</td>\n",
       "      <td>0.640012</td>\n",
       "      <td>2.216675</td>\n",
       "      <td>4.895009</td>\n",
       "      <td>-0.756911</td>\n",
       "      <td>0.601310</td>\n",
       "      <td>0.626161</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.973938</td>\n",
       "      <td>0.384216</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>-0.617335</td>\n",
       "      <td>-0.804824</td>\n",
       "      <td>2.118859</td>\n",
       "      <td>-0.027766</td>\n",
       "      <td>-0.705104</td>\n",
       "      <td>-0.903756</td>\n",
       "      <td>-0.074229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.738639</td>\n",
       "      <td>4.480778</td>\n",
       "      <td>-0.299590</td>\n",
       "      <td>2.453547</td>\n",
       "      <td>2.878191</td>\n",
       "      <td>-1.954515</td>\n",
       "      <td>-2.745203</td>\n",
       "      <td>2.053140</td>\n",
       "      <td>1.303837</td>\n",
       "      <td>1.096262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016199</td>\n",
       "      <td>0.610684</td>\n",
       "      <td>1.745640</td>\n",
       "      <td>-1.347220</td>\n",
       "      <td>0.511592</td>\n",
       "      <td>1.973714</td>\n",
       "      <td>-2.418103</td>\n",
       "      <td>-1.408296</td>\n",
       "      <td>-1.256017</td>\n",
       "      <td>-0.212105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-4.020566</td>\n",
       "      <td>2.218002</td>\n",
       "      <td>0.505875</td>\n",
       "      <td>4.265441</td>\n",
       "      <td>1.748757</td>\n",
       "      <td>-3.741759</td>\n",
       "      <td>1.322408</td>\n",
       "      <td>2.108941</td>\n",
       "      <td>1.953548</td>\n",
       "      <td>-0.379963</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.359872</td>\n",
       "      <td>0.179252</td>\n",
       "      <td>1.012260</td>\n",
       "      <td>0.367134</td>\n",
       "      <td>-0.280339</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>1.771880</td>\n",
       "      <td>-0.134368</td>\n",
       "      <td>1.646408</td>\n",
       "      <td>-1.860133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.125679</td>\n",
       "      <td>-1.366288</td>\n",
       "      <td>0.193857</td>\n",
       "      <td>-2.117797</td>\n",
       "      <td>-3.063484</td>\n",
       "      <td>-5.037376</td>\n",
       "      <td>3.176363</td>\n",
       "      <td>0.279970</td>\n",
       "      <td>-1.811660</td>\n",
       "      <td>-0.163485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046451</td>\n",
       "      <td>-0.435587</td>\n",
       "      <td>0.380961</td>\n",
       "      <td>1.182114</td>\n",
       "      <td>-0.383276</td>\n",
       "      <td>0.216497</td>\n",
       "      <td>-1.040882</td>\n",
       "      <td>1.172556</td>\n",
       "      <td>1.327903</td>\n",
       "      <td>0.407652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.800979</td>\n",
       "      <td>-2.241031</td>\n",
       "      <td>-2.688866</td>\n",
       "      <td>-2.196893</td>\n",
       "      <td>3.443118</td>\n",
       "      <td>-2.813406</td>\n",
       "      <td>0.796966</td>\n",
       "      <td>-0.727323</td>\n",
       "      <td>0.253297</td>\n",
       "      <td>-3.780845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313346</td>\n",
       "      <td>-3.398208</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>-0.219703</td>\n",
       "      <td>0.459047</td>\n",
       "      <td>-0.155727</td>\n",
       "      <td>1.169016</td>\n",
       "      <td>-0.415713</td>\n",
       "      <td>-0.648650</td>\n",
       "      <td>0.556651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.859934</td>\n",
       "      <td>0.561668</td>\n",
       "      <td>-0.882598</td>\n",
       "      <td>0.593626</td>\n",
       "      <td>3.839954</td>\n",
       "      <td>-4.542864</td>\n",
       "      <td>-1.679549</td>\n",
       "      <td>-0.105918</td>\n",
       "      <td>2.373693</td>\n",
       "      <td>-2.231371</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.228149</td>\n",
       "      <td>-2.201966</td>\n",
       "      <td>-1.180812</td>\n",
       "      <td>1.760369</td>\n",
       "      <td>0.330136</td>\n",
       "      <td>1.517145</td>\n",
       "      <td>-2.663098</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>-1.122349</td>\n",
       "      <td>-0.549464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.831579</td>\n",
       "      <td>-0.517408</td>\n",
       "      <td>-2.872165</td>\n",
       "      <td>0.435718</td>\n",
       "      <td>-0.922932</td>\n",
       "      <td>-6.866651</td>\n",
       "      <td>-0.922333</td>\n",
       "      <td>-2.771447</td>\n",
       "      <td>2.414574</td>\n",
       "      <td>3.330211</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.200413</td>\n",
       "      <td>-0.043396</td>\n",
       "      <td>-1.507761</td>\n",
       "      <td>1.087443</td>\n",
       "      <td>1.548497</td>\n",
       "      <td>-0.996869</td>\n",
       "      <td>-0.516857</td>\n",
       "      <td>-1.316155</td>\n",
       "      <td>-0.531918</td>\n",
       "      <td>-0.431079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.053405</td>\n",
       "      <td>-0.518702</td>\n",
       "      <td>0.671452</td>\n",
       "      <td>-3.226281</td>\n",
       "      <td>-0.312666</td>\n",
       "      <td>-0.790325</td>\n",
       "      <td>4.273053</td>\n",
       "      <td>2.009268</td>\n",
       "      <td>0.461570</td>\n",
       "      <td>-1.979729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348502</td>\n",
       "      <td>-1.285761</td>\n",
       "      <td>-2.519264</td>\n",
       "      <td>-0.106786</td>\n",
       "      <td>-0.225728</td>\n",
       "      <td>-0.345845</td>\n",
       "      <td>-0.464598</td>\n",
       "      <td>0.724302</td>\n",
       "      <td>0.418547</td>\n",
       "      <td>-0.166983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.661947</td>\n",
       "      <td>3.787266</td>\n",
       "      <td>0.393040</td>\n",
       "      <td>-3.084554</td>\n",
       "      <td>1.003920</td>\n",
       "      <td>-6.584730</td>\n",
       "      <td>-6.939392</td>\n",
       "      <td>0.717513</td>\n",
       "      <td>2.831865</td>\n",
       "      <td>-0.308030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.784862</td>\n",
       "      <td>-0.997726</td>\n",
       "      <td>0.787801</td>\n",
       "      <td>0.033809</td>\n",
       "      <td>-1.171645</td>\n",
       "      <td>-0.856074</td>\n",
       "      <td>1.366275</td>\n",
       "      <td>0.194905</td>\n",
       "      <td>0.189587</td>\n",
       "      <td>0.880920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.986886</td>\n",
       "      <td>-0.883791</td>\n",
       "      <td>0.685189</td>\n",
       "      <td>-0.970869</td>\n",
       "      <td>-0.578814</td>\n",
       "      <td>-1.199088</td>\n",
       "      <td>-1.652704</td>\n",
       "      <td>-0.559369</td>\n",
       "      <td>-3.593433</td>\n",
       "      <td>0.693498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>-0.156619</td>\n",
       "      <td>-0.524636</td>\n",
       "      <td>-0.720271</td>\n",
       "      <td>-2.878713</td>\n",
       "      <td>0.101931</td>\n",
       "      <td>0.406329</td>\n",
       "      <td>-1.399034</td>\n",
       "      <td>-1.244075</td>\n",
       "      <td>0.831446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>-4.277083</td>\n",
       "      <td>1.578890</td>\n",
       "      <td>4.017778</td>\n",
       "      <td>-5.105430</td>\n",
       "      <td>-1.390410</td>\n",
       "      <td>1.602959</td>\n",
       "      <td>-3.234188</td>\n",
       "      <td>-3.605661</td>\n",
       "      <td>-2.339432</td>\n",
       "      <td>3.744605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277304</td>\n",
       "      <td>-0.485409</td>\n",
       "      <td>0.360421</td>\n",
       "      <td>1.689213</td>\n",
       "      <td>1.211842</td>\n",
       "      <td>1.658637</td>\n",
       "      <td>0.133695</td>\n",
       "      <td>-0.637716</td>\n",
       "      <td>-0.716937</td>\n",
       "      <td>-0.527250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>0.131336</td>\n",
       "      <td>3.506124</td>\n",
       "      <td>-0.412661</td>\n",
       "      <td>3.154823</td>\n",
       "      <td>0.472307</td>\n",
       "      <td>2.435980</td>\n",
       "      <td>-0.708144</td>\n",
       "      <td>4.025755</td>\n",
       "      <td>-1.540972</td>\n",
       "      <td>0.507001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.923049</td>\n",
       "      <td>-1.694689</td>\n",
       "      <td>-1.143023</td>\n",
       "      <td>1.030988</td>\n",
       "      <td>-0.567748</td>\n",
       "      <td>-0.124197</td>\n",
       "      <td>-1.636202</td>\n",
       "      <td>1.207443</td>\n",
       "      <td>-1.839501</td>\n",
       "      <td>0.577203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>3.305118</td>\n",
       "      <td>-2.672293</td>\n",
       "      <td>0.247140</td>\n",
       "      <td>3.361052</td>\n",
       "      <td>3.293495</td>\n",
       "      <td>4.100495</td>\n",
       "      <td>-4.590888</td>\n",
       "      <td>-0.445438</td>\n",
       "      <td>0.803447</td>\n",
       "      <td>1.225431</td>\n",
       "      <td>...</td>\n",
       "      <td>2.056823</td>\n",
       "      <td>-0.984812</td>\n",
       "      <td>-0.239922</td>\n",
       "      <td>-0.156562</td>\n",
       "      <td>-1.224878</td>\n",
       "      <td>1.511698</td>\n",
       "      <td>-2.736534</td>\n",
       "      <td>-0.846529</td>\n",
       "      <td>0.990862</td>\n",
       "      <td>-1.261693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>-3.504898</td>\n",
       "      <td>4.147832</td>\n",
       "      <td>1.740829</td>\n",
       "      <td>2.868251</td>\n",
       "      <td>-3.788198</td>\n",
       "      <td>-1.046596</td>\n",
       "      <td>0.997221</td>\n",
       "      <td>0.531355</td>\n",
       "      <td>-3.707046</td>\n",
       "      <td>-1.445275</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078899</td>\n",
       "      <td>1.887029</td>\n",
       "      <td>0.413268</td>\n",
       "      <td>-0.187738</td>\n",
       "      <td>-0.393750</td>\n",
       "      <td>-0.669286</td>\n",
       "      <td>-0.351248</td>\n",
       "      <td>-2.049816</td>\n",
       "      <td>1.562092</td>\n",
       "      <td>1.728139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>-2.164739</td>\n",
       "      <td>-0.140156</td>\n",
       "      <td>-0.363340</td>\n",
       "      <td>-4.023095</td>\n",
       "      <td>1.143442</td>\n",
       "      <td>2.672037</td>\n",
       "      <td>-2.750572</td>\n",
       "      <td>0.534011</td>\n",
       "      <td>2.767338</td>\n",
       "      <td>1.486527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001762</td>\n",
       "      <td>-0.421702</td>\n",
       "      <td>1.926896</td>\n",
       "      <td>-0.978277</td>\n",
       "      <td>-0.353847</td>\n",
       "      <td>-1.585066</td>\n",
       "      <td>1.059207</td>\n",
       "      <td>0.552209</td>\n",
       "      <td>3.111579</td>\n",
       "      <td>0.802079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>-5.874215</td>\n",
       "      <td>-0.432911</td>\n",
       "      <td>-0.542905</td>\n",
       "      <td>1.395546</td>\n",
       "      <td>-1.193705</td>\n",
       "      <td>0.469269</td>\n",
       "      <td>-0.945734</td>\n",
       "      <td>-1.159904</td>\n",
       "      <td>-1.974428</td>\n",
       "      <td>-0.221890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>-0.780449</td>\n",
       "      <td>0.526926</td>\n",
       "      <td>1.300073</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>-1.748011</td>\n",
       "      <td>0.726763</td>\n",
       "      <td>0.188030</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-2.763877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>3.812919</td>\n",
       "      <td>-0.319369</td>\n",
       "      <td>1.769495</td>\n",
       "      <td>-3.736956</td>\n",
       "      <td>-2.287870</td>\n",
       "      <td>0.742762</td>\n",
       "      <td>-2.758872</td>\n",
       "      <td>3.828723</td>\n",
       "      <td>-0.361518</td>\n",
       "      <td>-0.498899</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.139912</td>\n",
       "      <td>-2.555548</td>\n",
       "      <td>1.055979</td>\n",
       "      <td>0.510272</td>\n",
       "      <td>2.441269</td>\n",
       "      <td>0.383868</td>\n",
       "      <td>2.080617</td>\n",
       "      <td>-1.501040</td>\n",
       "      <td>-0.513809</td>\n",
       "      <td>1.647414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>-1.092805</td>\n",
       "      <td>1.259704</td>\n",
       "      <td>-2.960041</td>\n",
       "      <td>3.347475</td>\n",
       "      <td>0.490572</td>\n",
       "      <td>2.627319</td>\n",
       "      <td>-0.659929</td>\n",
       "      <td>4.287224</td>\n",
       "      <td>0.059988</td>\n",
       "      <td>1.907073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.748788</td>\n",
       "      <td>-2.735826</td>\n",
       "      <td>-0.744201</td>\n",
       "      <td>1.159132</td>\n",
       "      <td>-0.720509</td>\n",
       "      <td>-0.109362</td>\n",
       "      <td>-1.587520</td>\n",
       "      <td>1.545733</td>\n",
       "      <td>-1.640634</td>\n",
       "      <td>0.759900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2.805762</td>\n",
       "      <td>-3.085835</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>2.682937</td>\n",
       "      <td>1.489075</td>\n",
       "      <td>4.784736</td>\n",
       "      <td>-4.314124</td>\n",
       "      <td>0.865651</td>\n",
       "      <td>0.743618</td>\n",
       "      <td>1.302879</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678962</td>\n",
       "      <td>-1.408554</td>\n",
       "      <td>-0.288794</td>\n",
       "      <td>0.564763</td>\n",
       "      <td>-1.241411</td>\n",
       "      <td>1.194381</td>\n",
       "      <td>-2.912554</td>\n",
       "      <td>-1.044141</td>\n",
       "      <td>0.893718</td>\n",
       "      <td>-1.357568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>3.218838</td>\n",
       "      <td>-1.282458</td>\n",
       "      <td>-1.460453</td>\n",
       "      <td>-1.603159</td>\n",
       "      <td>-1.223091</td>\n",
       "      <td>0.929968</td>\n",
       "      <td>-2.599398</td>\n",
       "      <td>3.476855</td>\n",
       "      <td>-1.147123</td>\n",
       "      <td>-0.323604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769637</td>\n",
       "      <td>-1.814686</td>\n",
       "      <td>0.840200</td>\n",
       "      <td>0.231586</td>\n",
       "      <td>2.294619</td>\n",
       "      <td>0.743759</td>\n",
       "      <td>2.332848</td>\n",
       "      <td>-1.561472</td>\n",
       "      <td>-0.402797</td>\n",
       "      <td>1.513552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>-3.482905</td>\n",
       "      <td>-2.131938</td>\n",
       "      <td>-0.337890</td>\n",
       "      <td>-0.284257</td>\n",
       "      <td>0.122411</td>\n",
       "      <td>-2.520555</td>\n",
       "      <td>-1.991696</td>\n",
       "      <td>2.558575</td>\n",
       "      <td>-1.158459</td>\n",
       "      <td>0.353374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819090</td>\n",
       "      <td>-2.204437</td>\n",
       "      <td>0.878662</td>\n",
       "      <td>-0.145615</td>\n",
       "      <td>-0.527635</td>\n",
       "      <td>-0.409795</td>\n",
       "      <td>1.705990</td>\n",
       "      <td>0.969100</td>\n",
       "      <td>1.878787</td>\n",
       "      <td>-1.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>-4.431358</td>\n",
       "      <td>-5.047854</td>\n",
       "      <td>-0.963282</td>\n",
       "      <td>0.777718</td>\n",
       "      <td>1.395134</td>\n",
       "      <td>3.351961</td>\n",
       "      <td>-0.457628</td>\n",
       "      <td>2.988323</td>\n",
       "      <td>-3.891133</td>\n",
       "      <td>2.132906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486824</td>\n",
       "      <td>-1.497514</td>\n",
       "      <td>2.404243</td>\n",
       "      <td>-1.930051</td>\n",
       "      <td>1.212788</td>\n",
       "      <td>0.589948</td>\n",
       "      <td>-3.149780</td>\n",
       "      <td>-0.835510</td>\n",
       "      <td>-0.204842</td>\n",
       "      <td>-0.396804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>-3.916516</td>\n",
       "      <td>-0.602440</td>\n",
       "      <td>-1.225255</td>\n",
       "      <td>-1.407840</td>\n",
       "      <td>0.575499</td>\n",
       "      <td>-3.476035</td>\n",
       "      <td>-2.061121</td>\n",
       "      <td>3.107546</td>\n",
       "      <td>-1.185498</td>\n",
       "      <td>-0.714928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489659</td>\n",
       "      <td>-2.258207</td>\n",
       "      <td>1.268286</td>\n",
       "      <td>-0.136702</td>\n",
       "      <td>-0.228654</td>\n",
       "      <td>-0.368411</td>\n",
       "      <td>1.729955</td>\n",
       "      <td>0.807845</td>\n",
       "      <td>1.960333</td>\n",
       "      <td>-1.585323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>-2.626203</td>\n",
       "      <td>-6.016338</td>\n",
       "      <td>-2.178400</td>\n",
       "      <td>3.340647</td>\n",
       "      <td>0.196152</td>\n",
       "      <td>3.707415</td>\n",
       "      <td>0.456180</td>\n",
       "      <td>2.142990</td>\n",
       "      <td>-2.481176</td>\n",
       "      <td>1.947960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114899</td>\n",
       "      <td>-1.532517</td>\n",
       "      <td>2.956233</td>\n",
       "      <td>-1.921185</td>\n",
       "      <td>0.919852</td>\n",
       "      <td>0.652157</td>\n",
       "      <td>-3.091743</td>\n",
       "      <td>-0.494569</td>\n",
       "      <td>-0.180240</td>\n",
       "      <td>-0.363481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0.337375</td>\n",
       "      <td>3.490159</td>\n",
       "      <td>-0.723958</td>\n",
       "      <td>0.644453</td>\n",
       "      <td>-4.993856</td>\n",
       "      <td>2.824404</td>\n",
       "      <td>-4.927249</td>\n",
       "      <td>-0.706197</td>\n",
       "      <td>-3.171391</td>\n",
       "      <td>0.952786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321455</td>\n",
       "      <td>0.178111</td>\n",
       "      <td>0.156367</td>\n",
       "      <td>1.062863</td>\n",
       "      <td>1.814635</td>\n",
       "      <td>0.936057</td>\n",
       "      <td>2.377768</td>\n",
       "      <td>-0.674273</td>\n",
       "      <td>-0.598899</td>\n",
       "      <td>-0.334322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>-3.096622</td>\n",
       "      <td>6.945202</td>\n",
       "      <td>-1.939499</td>\n",
       "      <td>3.426427</td>\n",
       "      <td>-5.422765</td>\n",
       "      <td>-0.384871</td>\n",
       "      <td>-0.692151</td>\n",
       "      <td>-1.451047</td>\n",
       "      <td>-0.365363</td>\n",
       "      <td>-0.943289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.786902</td>\n",
       "      <td>-0.762898</td>\n",
       "      <td>-0.064145</td>\n",
       "      <td>0.901696</td>\n",
       "      <td>-0.649768</td>\n",
       "      <td>0.331368</td>\n",
       "      <td>-2.702418</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>-0.955701</td>\n",
       "      <td>1.660476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>-0.655826</td>\n",
       "      <td>1.988560</td>\n",
       "      <td>-1.394084</td>\n",
       "      <td>1.187616</td>\n",
       "      <td>-5.106056</td>\n",
       "      <td>3.679580</td>\n",
       "      <td>-4.338863</td>\n",
       "      <td>-0.394434</td>\n",
       "      <td>-3.123062</td>\n",
       "      <td>-0.212285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535572</td>\n",
       "      <td>0.135573</td>\n",
       "      <td>-0.447033</td>\n",
       "      <td>0.672918</td>\n",
       "      <td>1.276258</td>\n",
       "      <td>1.193670</td>\n",
       "      <td>2.637395</td>\n",
       "      <td>-0.394811</td>\n",
       "      <td>-0.486582</td>\n",
       "      <td>-0.180287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>-3.305682</td>\n",
       "      <td>3.667691</td>\n",
       "      <td>-3.633221</td>\n",
       "      <td>4.916392</td>\n",
       "      <td>-3.622202</td>\n",
       "      <td>-1.200530</td>\n",
       "      <td>-1.041756</td>\n",
       "      <td>-1.630927</td>\n",
       "      <td>-0.207848</td>\n",
       "      <td>-0.129225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332240</td>\n",
       "      <td>-1.305547</td>\n",
       "      <td>0.435519</td>\n",
       "      <td>0.457773</td>\n",
       "      <td>-0.985244</td>\n",
       "      <td>0.490847</td>\n",
       "      <td>-2.240857</td>\n",
       "      <td>0.361020</td>\n",
       "      <td>-0.995602</td>\n",
       "      <td>2.009468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>-3.596611</td>\n",
       "      <td>-5.418763</td>\n",
       "      <td>-2.989533</td>\n",
       "      <td>4.884651</td>\n",
       "      <td>-0.499611</td>\n",
       "      <td>3.746198</td>\n",
       "      <td>0.553778</td>\n",
       "      <td>1.172541</td>\n",
       "      <td>-1.843720</td>\n",
       "      <td>1.535098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349347</td>\n",
       "      <td>-1.641027</td>\n",
       "      <td>2.715020</td>\n",
       "      <td>-1.799611</td>\n",
       "      <td>1.110880</td>\n",
       "      <td>0.703870</td>\n",
       "      <td>-3.237865</td>\n",
       "      <td>-0.600391</td>\n",
       "      <td>-0.280594</td>\n",
       "      <td>-0.662236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>-4.045434</td>\n",
       "      <td>-0.901079</td>\n",
       "      <td>-2.552756</td>\n",
       "      <td>-0.736315</td>\n",
       "      <td>0.506479</td>\n",
       "      <td>-2.298144</td>\n",
       "      <td>0.200083</td>\n",
       "      <td>1.830467</td>\n",
       "      <td>-1.648035</td>\n",
       "      <td>-0.386603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486499</td>\n",
       "      <td>-1.672982</td>\n",
       "      <td>1.583306</td>\n",
       "      <td>-0.191972</td>\n",
       "      <td>-0.461373</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>1.989284</td>\n",
       "      <td>0.789846</td>\n",
       "      <td>1.782527</td>\n",
       "      <td>-1.526303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0.600421</td>\n",
       "      <td>-0.005900</td>\n",
       "      <td>0.381294</td>\n",
       "      <td>1.871617</td>\n",
       "      <td>-5.559740</td>\n",
       "      <td>6.025298</td>\n",
       "      <td>-2.847511</td>\n",
       "      <td>0.064890</td>\n",
       "      <td>-3.812198</td>\n",
       "      <td>0.484526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.457495</td>\n",
       "      <td>-0.496443</td>\n",
       "      <td>-0.826340</td>\n",
       "      <td>0.984233</td>\n",
       "      <td>1.103708</td>\n",
       "      <td>1.055200</td>\n",
       "      <td>2.764112</td>\n",
       "      <td>-0.003711</td>\n",
       "      <td>-0.162027</td>\n",
       "      <td>-0.197613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>-1.400503</td>\n",
       "      <td>2.446609</td>\n",
       "      <td>-3.280557</td>\n",
       "      <td>6.799994</td>\n",
       "      <td>-0.892753</td>\n",
       "      <td>-2.606629</td>\n",
       "      <td>-1.305420</td>\n",
       "      <td>-2.692749</td>\n",
       "      <td>0.094505</td>\n",
       "      <td>-0.920959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338422</td>\n",
       "      <td>-2.242637</td>\n",
       "      <td>0.563330</td>\n",
       "      <td>0.829720</td>\n",
       "      <td>-0.936069</td>\n",
       "      <td>0.612462</td>\n",
       "      <td>-2.268590</td>\n",
       "      <td>0.520147</td>\n",
       "      <td>-0.622200</td>\n",
       "      <td>2.100481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>-3.906296</td>\n",
       "      <td>0.129470</td>\n",
       "      <td>0.204212</td>\n",
       "      <td>-0.361035</td>\n",
       "      <td>0.629779</td>\n",
       "      <td>-0.889922</td>\n",
       "      <td>-0.200555</td>\n",
       "      <td>0.356769</td>\n",
       "      <td>-1.384658</td>\n",
       "      <td>0.407534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461566</td>\n",
       "      <td>-1.663450</td>\n",
       "      <td>1.967818</td>\n",
       "      <td>-0.310726</td>\n",
       "      <td>-0.446272</td>\n",
       "      <td>-0.358352</td>\n",
       "      <td>2.085682</td>\n",
       "      <td>0.905820</td>\n",
       "      <td>1.690445</td>\n",
       "      <td>-1.375342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>-4.520226</td>\n",
       "      <td>0.347049</td>\n",
       "      <td>2.268534</td>\n",
       "      <td>0.060809</td>\n",
       "      <td>-3.059166</td>\n",
       "      <td>4.740799</td>\n",
       "      <td>-0.728032</td>\n",
       "      <td>-0.615112</td>\n",
       "      <td>-4.033454</td>\n",
       "      <td>0.643841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479975</td>\n",
       "      <td>-1.076551</td>\n",
       "      <td>0.866490</td>\n",
       "      <td>1.057437</td>\n",
       "      <td>-0.352476</td>\n",
       "      <td>0.232866</td>\n",
       "      <td>2.754515</td>\n",
       "      <td>1.074570</td>\n",
       "      <td>0.408037</td>\n",
       "      <td>-2.024260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>-5.204002</td>\n",
       "      <td>-0.107649</td>\n",
       "      <td>2.964431</td>\n",
       "      <td>-1.307106</td>\n",
       "      <td>-2.000702</td>\n",
       "      <td>2.928155</td>\n",
       "      <td>-1.439571</td>\n",
       "      <td>-0.312006</td>\n",
       "      <td>-2.258000</td>\n",
       "      <td>1.753716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340037</td>\n",
       "      <td>-1.327208</td>\n",
       "      <td>0.863486</td>\n",
       "      <td>1.148718</td>\n",
       "      <td>-0.126814</td>\n",
       "      <td>0.274323</td>\n",
       "      <td>2.462793</td>\n",
       "      <td>0.920959</td>\n",
       "      <td>0.343013</td>\n",
       "      <td>-2.114909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>-4.674644</td>\n",
       "      <td>-0.240755</td>\n",
       "      <td>-3.057182</td>\n",
       "      <td>5.896494</td>\n",
       "      <td>-1.740915</td>\n",
       "      <td>0.821305</td>\n",
       "      <td>-0.482391</td>\n",
       "      <td>-3.011306</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-1.320127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473721</td>\n",
       "      <td>-1.006054</td>\n",
       "      <td>2.167669</td>\n",
       "      <td>-2.962881</td>\n",
       "      <td>0.604771</td>\n",
       "      <td>0.348462</td>\n",
       "      <td>-2.922065</td>\n",
       "      <td>-1.076453</td>\n",
       "      <td>0.167188</td>\n",
       "      <td>1.335712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>-3.103196</td>\n",
       "      <td>-0.029626</td>\n",
       "      <td>-1.752651</td>\n",
       "      <td>5.346659</td>\n",
       "      <td>-0.634508</td>\n",
       "      <td>2.050368</td>\n",
       "      <td>-0.193862</td>\n",
       "      <td>-2.238958</td>\n",
       "      <td>-1.257364</td>\n",
       "      <td>-2.566511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558974</td>\n",
       "      <td>-0.261909</td>\n",
       "      <td>2.020886</td>\n",
       "      <td>-2.575236</td>\n",
       "      <td>0.356338</td>\n",
       "      <td>0.216902</td>\n",
       "      <td>-3.018051</td>\n",
       "      <td>-1.079308</td>\n",
       "      <td>0.279611</td>\n",
       "      <td>1.215818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>-3.431881</td>\n",
       "      <td>-2.357465</td>\n",
       "      <td>4.147610</td>\n",
       "      <td>0.203519</td>\n",
       "      <td>1.186894</td>\n",
       "      <td>1.659249</td>\n",
       "      <td>-0.829609</td>\n",
       "      <td>-0.048395</td>\n",
       "      <td>-2.280089</td>\n",
       "      <td>1.298246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155824</td>\n",
       "      <td>-1.284128</td>\n",
       "      <td>1.062099</td>\n",
       "      <td>0.886628</td>\n",
       "      <td>0.318705</td>\n",
       "      <td>0.103770</td>\n",
       "      <td>2.301660</td>\n",
       "      <td>1.086085</td>\n",
       "      <td>0.498239</td>\n",
       "      <td>-2.012480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>-4.778056</td>\n",
       "      <td>1.532425</td>\n",
       "      <td>-2.028306</td>\n",
       "      <td>4.145721</td>\n",
       "      <td>-0.963184</td>\n",
       "      <td>2.545959</td>\n",
       "      <td>-1.288378</td>\n",
       "      <td>-2.132792</td>\n",
       "      <td>-2.005299</td>\n",
       "      <td>-1.409712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036697</td>\n",
       "      <td>0.405173</td>\n",
       "      <td>0.638478</td>\n",
       "      <td>-2.565376</td>\n",
       "      <td>0.668495</td>\n",
       "      <td>0.411039</td>\n",
       "      <td>-3.247691</td>\n",
       "      <td>-1.199095</td>\n",
       "      <td>0.056932</td>\n",
       "      <td>1.140915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>-2.354316</td>\n",
       "      <td>-3.279350</td>\n",
       "      <td>3.454386</td>\n",
       "      <td>-0.349776</td>\n",
       "      <td>1.903686</td>\n",
       "      <td>0.182685</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>-0.297713</td>\n",
       "      <td>-1.750813</td>\n",
       "      <td>1.025745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383968</td>\n",
       "      <td>-2.229750</td>\n",
       "      <td>1.327196</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.051639</td>\n",
       "      <td>2.180087</td>\n",
       "      <td>1.253901</td>\n",
       "      <td>0.714254</td>\n",
       "      <td>-2.050729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     1.982755 -4.115200  1.406928 -3.757984  3.656259  1.613922 -1.890569   \n",
       "1     3.607682  7.496757  3.454382  5.037950 -0.579141 -0.176741  0.166539   \n",
       "2     3.997884 -3.165365 -4.122333 -1.276138  0.118351 -2.938084  2.389109   \n",
       "3     5.748678 -1.478169 -0.594992 -4.158985  2.174499 -0.259768  2.037785   \n",
       "4     8.887310 -5.232141  2.010836  1.554207 -0.550797  3.529540  5.317237   \n",
       "5     3.572635  0.986207  2.006660 -1.515516 -1.117444 -2.525403  6.439270   \n",
       "6     4.259470  0.098404 -0.458336  1.818204 -1.858724 -3.302179 -0.893786   \n",
       "7    -3.839558  3.130066  0.852576  0.694067 -3.162966 -4.763087  1.578844   \n",
       "8     5.849369 -0.710844 -0.011611  2.792113  5.369946  2.842351  2.248036   \n",
       "9    -5.319738  2.343567  1.054355  5.043071  1.911188 -6.283395 -0.080140   \n",
       "10    2.421684  5.522900 -3.426086 -5.876746  3.418981 -9.293457 -4.082693   \n",
       "11    2.073767 -1.200186 -2.275805 -0.260582 -3.027405 -2.950029  0.180111   \n",
       "12    5.991178  1.183007  4.047436  1.011372 -0.554906 -2.954260  0.918956   \n",
       "13    7.364150  2.678412 -0.862547 -4.093276 -3.437406 -1.767157  1.156182   \n",
       "14   -3.521345  0.174426  2.732667  2.109188  0.179922 -1.246286 -0.219240   \n",
       "15    5.737193  1.076513  2.423806  6.504006  4.087897 -2.799494 -0.608417   \n",
       "16    4.406272  1.945512 -1.325678  1.700711 -1.715407 -2.369002  2.310580   \n",
       "17   -0.252831  0.442091  1.580202  0.383030 -0.848218  0.009637  0.944963   \n",
       "18    2.551387 -3.945093  2.828089  0.274768 -2.269408 -3.895442  1.719025   \n",
       "19    2.017185 -3.163206 -1.029822  2.439137  1.135837 -3.118376  1.950225   \n",
       "20    2.407621 -5.456649  2.148830 -3.605895  0.640012  2.216675  4.895009   \n",
       "21    0.738639  4.480778 -0.299590  2.453547  2.878191 -1.954515 -2.745203   \n",
       "22   -4.020566  2.218002  0.505875  4.265441  1.748757 -3.741759  1.322408   \n",
       "23    4.125679 -1.366288  0.193857 -2.117797 -3.063484 -5.037376  3.176363   \n",
       "24    3.800979 -2.241031 -2.688866 -2.196893  3.443118 -2.813406  0.796966   \n",
       "25   -2.859934  0.561668 -0.882598  0.593626  3.839954 -4.542864 -1.679549   \n",
       "26    0.831579 -0.517408 -2.872165  0.435718 -0.922932 -6.866651 -0.922333   \n",
       "27    2.053405 -0.518702  0.671452 -3.226281 -0.312666 -0.790325  4.273053   \n",
       "28    1.661947  3.787266  0.393040 -3.084554  1.003920 -6.584730 -6.939392   \n",
       "29    5.986886 -0.883791  0.685189 -0.970869 -0.578814 -1.199088 -1.652704   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1245 -4.277083  1.578890  4.017778 -5.105430 -1.390410  1.602959 -3.234188   \n",
       "1246  0.131336  3.506124 -0.412661  3.154823  0.472307  2.435980 -0.708144   \n",
       "1247  3.305118 -2.672293  0.247140  3.361052  3.293495  4.100495 -4.590888   \n",
       "1248 -3.504898  4.147832  1.740829  2.868251 -3.788198 -1.046596  0.997221   \n",
       "1249 -2.164739 -0.140156 -0.363340 -4.023095  1.143442  2.672037 -2.750572   \n",
       "1250 -5.874215 -0.432911 -0.542905  1.395546 -1.193705  0.469269 -0.945734   \n",
       "1251  3.812919 -0.319369  1.769495 -3.736956 -2.287870  0.742762 -2.758872   \n",
       "1252 -1.092805  1.259704 -2.960041  3.347475  0.490572  2.627319 -0.659929   \n",
       "1253  2.805762 -3.085835  0.001473  2.682937  1.489075  4.784736 -4.314124   \n",
       "1254  3.218838 -1.282458 -1.460453 -1.603159 -1.223091  0.929968 -2.599398   \n",
       "1255 -3.482905 -2.131938 -0.337890 -0.284257  0.122411 -2.520555 -1.991696   \n",
       "1256 -4.431358 -5.047854 -0.963282  0.777718  1.395134  3.351961 -0.457628   \n",
       "1257 -3.916516 -0.602440 -1.225255 -1.407840  0.575499 -3.476035 -2.061121   \n",
       "1258 -2.626203 -6.016338 -2.178400  3.340647  0.196152  3.707415  0.456180   \n",
       "1259  0.337375  3.490159 -0.723958  0.644453 -4.993856  2.824404 -4.927249   \n",
       "1260 -3.096622  6.945202 -1.939499  3.426427 -5.422765 -0.384871 -0.692151   \n",
       "1261 -0.655826  1.988560 -1.394084  1.187616 -5.106056  3.679580 -4.338863   \n",
       "1262 -3.305682  3.667691 -3.633221  4.916392 -3.622202 -1.200530 -1.041756   \n",
       "1263 -3.596611 -5.418763 -2.989533  4.884651 -0.499611  3.746198  0.553778   \n",
       "1264 -4.045434 -0.901079 -2.552756 -0.736315  0.506479 -2.298144  0.200083   \n",
       "1265  0.600421 -0.005900  0.381294  1.871617 -5.559740  6.025298 -2.847511   \n",
       "1266 -1.400503  2.446609 -3.280557  6.799994 -0.892753 -2.606629 -1.305420   \n",
       "1267 -3.906296  0.129470  0.204212 -0.361035  0.629779 -0.889922 -0.200555   \n",
       "1268 -4.520226  0.347049  2.268534  0.060809 -3.059166  4.740799 -0.728032   \n",
       "1269 -5.204002 -0.107649  2.964431 -1.307106 -2.000702  2.928155 -1.439571   \n",
       "1270 -4.674644 -0.240755 -3.057182  5.896494 -1.740915  0.821305 -0.482391   \n",
       "1271 -3.103196 -0.029626 -1.752651  5.346659 -0.634508  2.050368 -0.193862   \n",
       "1272 -3.431881 -2.357465  4.147610  0.203519  1.186894  1.659249 -0.829609   \n",
       "1273 -4.778056  1.532425 -2.028306  4.145721 -0.963184  2.545959 -1.288378   \n",
       "1274 -2.354316 -3.279350  3.454386 -0.349776  1.903686  0.182685 -0.002966   \n",
       "\n",
       "            7         8         9     ...           20        21        22  \\\n",
       "0    -2.622225 -2.661984  2.518709    ...    -0.738718 -0.023524 -0.969870   \n",
       "1     0.840192  0.313012  1.047595    ...     0.918762 -0.638830  1.385301   \n",
       "2    -0.843803 -1.732838 -4.986368    ...    -2.204822  0.755812 -0.722123   \n",
       "3     0.962816 -0.378658  1.723109    ...    -1.596054  0.155321 -1.061750   \n",
       "4     0.790587 -0.670597 -2.453734    ...    -3.607736  0.351768  0.106923   \n",
       "5     0.794542  1.419729  0.457019    ...    -1.113163 -3.563197 -0.602929   \n",
       "6    -0.698713 -3.780284  2.449144    ...    -0.878282  0.947494 -1.596418   \n",
       "7     0.565021  3.119084 -4.506019    ...    -2.034292 -0.095932 -2.281433   \n",
       "8     3.087862  2.111505 -4.127600    ...     2.397921  0.228280 -0.146146   \n",
       "9     1.584919  4.934165  3.112176    ...    -0.760758  0.586755  0.508197   \n",
       "10   -1.709574 -0.736761  2.179015    ...    -0.514239 -2.182177  1.086405   \n",
       "11   -2.948363  0.541833  1.694014    ...     1.483620 -0.727931  0.340058   \n",
       "12    2.620994  2.008918 -2.200251    ...    -1.815877 -2.802456 -1.800421   \n",
       "13   -3.130842 -2.050123  1.328194    ...    -0.430343  2.738608  0.924460   \n",
       "14    0.980361  1.631902 -0.163416    ...    -1.962625 -0.704194 -1.626188   \n",
       "15   -1.382329  0.298526 -0.555837    ...     2.575143  1.405744  2.100426   \n",
       "16    0.173924 -1.862845  0.439541    ...     0.285021  0.292112 -2.731116   \n",
       "17   -1.410303  2.463184 -0.229165    ...     1.359755 -0.000592 -2.600352   \n",
       "18    0.914404 -0.806722 -3.125392    ...    -0.180487  1.046214 -3.115611   \n",
       "19    0.166213  0.533472 -1.182007    ...     2.471908  2.681405  0.156003   \n",
       "20   -0.756911  0.601310  0.626161    ...    -2.973938  0.384216  0.035333   \n",
       "21    2.053140  1.303837  1.096262    ...     0.016199  0.610684  1.745640   \n",
       "22    2.108941  1.953548 -0.379963    ...    -4.359872  0.179252  1.012260   \n",
       "23    0.279970 -1.811660 -0.163485    ...     0.046451 -0.435587  0.380961   \n",
       "24   -0.727323  0.253297 -3.780845    ...    -0.313346 -3.398208  0.047400   \n",
       "25   -0.105918  2.373693 -2.231371    ...    -1.228149 -2.201966 -1.180812   \n",
       "26   -2.771447  2.414574  3.330211    ...    -1.200413 -0.043396 -1.507761   \n",
       "27    2.009268  0.461570 -1.979729    ...     0.348502 -1.285761 -2.519264   \n",
       "28    0.717513  2.831865 -0.308030    ...    -0.784862 -0.997726  0.787801   \n",
       "29   -0.559369 -3.593433  0.693498    ...     0.004697 -0.156619 -0.524636   \n",
       "...        ...       ...       ...    ...          ...       ...       ...   \n",
       "1245 -3.605661 -2.339432  3.744605    ...    -0.277304 -0.485409  0.360421   \n",
       "1246  4.025755 -1.540972  0.507001    ...    -0.923049 -1.694689 -1.143023   \n",
       "1247 -0.445438  0.803447  1.225431    ...     2.056823 -0.984812 -0.239922   \n",
       "1248  0.531355 -3.707046 -1.445275    ...    -1.078899  1.887029  0.413268   \n",
       "1249  0.534011  2.767338  1.486527    ...    -0.001762 -0.421702  1.926896   \n",
       "1250 -1.159904 -1.974428 -0.221890    ...     0.014258 -0.780449  0.526926   \n",
       "1251  3.828723 -0.361518 -0.498899    ...    -1.139912 -2.555548  1.055979   \n",
       "1252  4.287224  0.059988  1.907073    ...    -0.748788 -2.735826 -0.744201   \n",
       "1253  0.865651  0.743618  1.302879    ...     1.678962 -1.408554 -0.288794   \n",
       "1254  3.476855 -1.147123 -0.323604    ...    -0.769637 -1.814686  0.840200   \n",
       "1255  2.558575 -1.158459  0.353374    ...     0.819090 -2.204437  0.878662   \n",
       "1256  2.988323 -3.891133  2.132906    ...    -0.486824 -1.497514  2.404243   \n",
       "1257  3.107546 -1.185498 -0.714928    ...     0.489659 -2.258207  1.268286   \n",
       "1258  2.142990 -2.481176  1.947960    ...     0.114899 -1.532517  2.956233   \n",
       "1259 -0.706197 -3.171391  0.952786    ...     0.321455  0.178111  0.156367   \n",
       "1260 -1.451047 -0.365363 -0.943289    ...    -0.786902 -0.762898 -0.064145   \n",
       "1261 -0.394434 -3.123062 -0.212285    ...     0.535572  0.135573 -0.447033   \n",
       "1262 -1.630927 -0.207848 -0.129225    ...    -0.332240 -1.305547  0.435519   \n",
       "1263  1.172541 -1.843720  1.535098    ...     0.349347 -1.641027  2.715020   \n",
       "1264  1.830467 -1.648035 -0.386603    ...     0.486499 -1.672982  1.583306   \n",
       "1265  0.064890 -3.812198  0.484526    ...     1.457495 -0.496443 -0.826340   \n",
       "1266 -2.692749  0.094505 -0.920959    ...    -0.338422 -2.242637  0.563330   \n",
       "1267  0.356769 -1.384658  0.407534    ...     0.461566 -1.663450  1.967818   \n",
       "1268 -0.615112 -4.033454  0.643841    ...     0.479975 -1.076551  0.866490   \n",
       "1269 -0.312006 -2.258000  1.753716    ...     0.340037 -1.327208  0.863486   \n",
       "1270 -3.011306 -0.098894 -1.320127    ...     0.473721 -1.006054  2.167669   \n",
       "1271 -2.238958 -1.257364 -2.566511    ...     0.558974 -0.261909  2.020886   \n",
       "1272 -0.048395 -2.280089  1.298246    ...     0.155824 -1.284128  1.062099   \n",
       "1273 -2.132792 -2.005299 -1.409712    ...     1.036697  0.405173  0.638478   \n",
       "1274 -0.297713 -1.750813  1.025745    ...    -0.383968 -2.229750  1.327196   \n",
       "\n",
       "            23        24        25        26        27        28        29  \n",
       "0    -0.562183 -1.216451  1.134578 -0.182661 -2.046463 -1.864370  0.570880  \n",
       "1    -0.052956 -0.145171  1.455080  1.075812  0.482158  1.494449 -1.311899  \n",
       "2    -1.416533  0.679098  1.199353  1.478558 -0.986917 -0.521556 -0.736711  \n",
       "3     2.784604 -2.075540  0.969271 -1.007516 -1.041927 -0.408836 -0.179374  \n",
       "4    -2.728456 -0.613580 -0.222306  1.070596  0.956270 -0.864357 -0.182315  \n",
       "5    -1.062612 -1.118831 -0.488971  0.149708  0.157637 -0.749770 -1.297730  \n",
       "6     1.719465  0.658379 -0.670800 -2.189380  0.263769  1.024148 -0.888278  \n",
       "7     1.199133 -0.307719 -0.223515 -0.735623 -0.330136 -1.119633 -1.172055  \n",
       "8     0.482149  0.261895  1.823439 -0.922943  1.771317 -0.703432 -0.097629  \n",
       "9     0.411074  1.018920 -1.094989  0.500371 -0.442784  0.931434 -1.870566  \n",
       "10    0.902301 -0.406464  0.282490 -0.333232  1.568376  2.374852  1.739884  \n",
       "11    0.912624 -3.061016 -2.632392  0.224033 -0.654526 -0.998330 -1.006495  \n",
       "12    0.069120 -0.627934 -0.522232 -0.016081  1.709427 -0.316162 -0.527561  \n",
       "13    0.234684  1.708144  0.750217  1.033675  0.581809  0.464666 -1.744320  \n",
       "14   -0.203017  0.792994  2.934628  0.772448  1.792112  2.018564  0.951161  \n",
       "15    1.144254  2.194890  0.333516  0.891670 -1.330217 -1.176694 -0.657595  \n",
       "16    0.098853 -0.615002 -1.209755 -0.771788 -0.781801  0.699097 -1.571110  \n",
       "17   -1.113253 -1.866813  0.915951 -0.334732  0.185686  1.400462 -1.802234  \n",
       "18    1.606211  1.432894 -0.732741 -0.827905  2.213189  0.715115 -1.003241  \n",
       "19    1.635769  0.004652 -1.486807  0.043597  0.240987  0.348562  0.926298  \n",
       "20   -0.617335 -0.804824  2.118859 -0.027766 -0.705104 -0.903756 -0.074229  \n",
       "21   -1.347220  0.511592  1.973714 -2.418103 -1.408296 -1.256017 -0.212105  \n",
       "22    0.367134 -0.280339 -0.090383  1.771880 -0.134368  1.646408 -1.860133  \n",
       "23    1.182114 -0.383276  0.216497 -1.040882  1.172556  1.327903  0.407652  \n",
       "24   -0.219703  0.459047 -0.155727  1.169016 -0.415713 -0.648650  0.556651  \n",
       "25    1.760369  0.330136  1.517145 -2.663098  0.003386 -1.122349 -0.549464  \n",
       "26    1.087443  1.548497 -0.996869 -0.516857 -1.316155 -0.531918 -0.431079  \n",
       "27   -0.106786 -0.225728 -0.345845 -0.464598  0.724302  0.418547 -0.166983  \n",
       "28    0.033809 -1.171645 -0.856074  1.366275  0.194905  0.189587  0.880920  \n",
       "29   -0.720271 -2.878713  0.101931  0.406329 -1.399034 -1.244075  0.831446  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1245  1.689213  1.211842  1.658637  0.133695 -0.637716 -0.716937 -0.527250  \n",
       "1246  1.030988 -0.567748 -0.124197 -1.636202  1.207443 -1.839501  0.577203  \n",
       "1247 -0.156562 -1.224878  1.511698 -2.736534 -0.846529  0.990862 -1.261693  \n",
       "1248 -0.187738 -0.393750 -0.669286 -0.351248 -2.049816  1.562092  1.728139  \n",
       "1249 -0.978277 -0.353847 -1.585066  1.059207  0.552209  3.111579  0.802079  \n",
       "1250  1.300073  0.058517 -1.748011  0.726763  0.188030 -0.804101 -2.763877  \n",
       "1251  0.510272  2.441269  0.383868  2.080617 -1.501040 -0.513809  1.647414  \n",
       "1252  1.159132 -0.720509 -0.109362 -1.587520  1.545733 -1.640634  0.759900  \n",
       "1253  0.564763 -1.241411  1.194381 -2.912554 -1.044141  0.893718 -1.357568  \n",
       "1254  0.231586  2.294619  0.743759  2.332848 -1.561472 -0.402797  1.513552  \n",
       "1255 -0.145615 -0.527635 -0.409795  1.705990  0.969100  1.878787 -1.627600  \n",
       "1256 -1.930051  1.212788  0.589948 -3.149780 -0.835510 -0.204842 -0.396804  \n",
       "1257 -0.136702 -0.228654 -0.368411  1.729955  0.807845  1.960333 -1.585323  \n",
       "1258 -1.921185  0.919852  0.652157 -3.091743 -0.494569 -0.180240 -0.363481  \n",
       "1259  1.062863  1.814635  0.936057  2.377768 -0.674273 -0.598899 -0.334322  \n",
       "1260  0.901696 -0.649768  0.331368 -2.702418  0.056152 -0.955701  1.660476  \n",
       "1261  0.672918  1.276258  1.193670  2.637395 -0.394811 -0.486582 -0.180287  \n",
       "1262  0.457773 -0.985244  0.490847 -2.240857  0.361020 -0.995602  2.009468  \n",
       "1263 -1.799611  1.110880  0.703870 -3.237865 -0.600391 -0.280594 -0.662236  \n",
       "1264 -0.191972 -0.461373 -0.005474  1.989284  0.789846  1.782527 -1.526303  \n",
       "1265  0.984233  1.103708  1.055200  2.764112 -0.003711 -0.162027 -0.197613  \n",
       "1266  0.829720 -0.936069  0.612462 -2.268590  0.520147 -0.622200  2.100481  \n",
       "1267 -0.310726 -0.446272 -0.358352  2.085682  0.905820  1.690445 -1.375342  \n",
       "1268  1.057437 -0.352476  0.232866  2.754515  1.074570  0.408037 -2.024260  \n",
       "1269  1.148718 -0.126814  0.274323  2.462793  0.920959  0.343013 -2.114909  \n",
       "1270 -2.962881  0.604771  0.348462 -2.922065 -1.076453  0.167188  1.335712  \n",
       "1271 -2.575236  0.356338  0.216902 -3.018051 -1.079308  0.279611  1.215818  \n",
       "1272  0.886628  0.318705  0.103770  2.301660  1.086085  0.498239 -2.012480  \n",
       "1273 -2.565376  0.668495  0.411039 -3.247691 -1.199095  0.056932  1.140915  \n",
       "1274  0.780935  0.630804  0.051639  2.180087  1.253901  0.714254 -2.050729  \n",
       "\n",
       "[1275 rows x 30 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_pcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# DB SCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 245)"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytarget.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dbscan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.5, min_samples=5,metric='euclidean', algorithm='auto', leaf_size=5, p=None, random_state=None)\n",
    "db_result = db.fit_predict(dbscan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(db_result).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(2)\n",
    "Kmean_result = km.fit_predict(dbscan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    203\n",
       "0    202\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Kmean_result).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-533728.97191757243"
      ]
     },
     "execution_count": 1289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.score(dbscan_data,mytarget.bad_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((406,), (405,))"
      ]
     },
     "execution_count": 1292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytarget.bad_games.shape, Kmean_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "\n",
    "for x,y in zip(mytarget.bad_games.values, Kmean_result):\n",
    "    if x == y:\n",
    "        correct += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbscan_data = mydata[[x for x in mydata.columns if not x in ['total_score','y_true','GuestName','HostName','winner','loser']]][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata['bad_games'] = mydata.myerror.apply(lambda x: 1 if x > 13 else 0)\n",
    "mytarget = mydata['bad_games'][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 241) (405,)\n"
     ]
    }
   ],
   "source": [
    "print dbscan_data.shape,mytarget.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Season',\n",
       " 'total_line',\n",
       " 'game_line',\n",
       " 'Host_HostRank',\n",
       " 'Host_GameRank',\n",
       " 'Guest_GuestRank',\n",
       " 'Guest_GameRank',\n",
       " 'Headsup_GameRank_Season',\n",
       " 'Headsup_GameRank_All',\n",
       " 'Host_LastGameDiff',\n",
       " 'Guest_LastGameDiff',\n",
       " 'host_win_count',\n",
       " 'host_lose_count',\n",
       " 'guest_win_count',\n",
       " 'guest_lose_count',\n",
       " 'game_behind',\n",
       " 'host_strike',\n",
       " 'guest_strike',\n",
       " 'host_place_streak',\n",
       " 'guest_place_streak',\n",
       " 'hq1_avg10',\n",
       " 'hq2_avg10',\n",
       " 'hq3_avg10',\n",
       " 'hq4_avg10',\n",
       " 'hPace_avg10',\n",
       " 'heFG%_avg10',\n",
       " 'hTOV%_avg10',\n",
       " 'hORB%_avg10',\n",
       " 'hFT/FGA_avg10',\n",
       " 'hORtg_avg10',\n",
       " 'hFG_avg10',\n",
       " 'hFGA_avg10',\n",
       " 'hFG%_avg10',\n",
       " 'h3P_avg10',\n",
       " 'h3PA_avg10',\n",
       " 'h3P%_avg10',\n",
       " 'hFT_avg10',\n",
       " 'hFTA_avg10',\n",
       " 'hFT%_avg10',\n",
       " 'hORB_avg10',\n",
       " 'hDRB_avg10',\n",
       " 'hTRB_avg10',\n",
       " 'hAST_avg10',\n",
       " 'hSTL_avg10',\n",
       " 'hBLK_avg10',\n",
       " 'hTOV_avg10',\n",
       " 'hPF_avg10',\n",
       " 'hPTS_avg10',\n",
       " 'hTS%_avg10',\n",
       " 'h3PAR_avg10',\n",
       " 'hFTr_avg10',\n",
       " 'hDRB%_avg10',\n",
       " 'hTRB%_avg10',\n",
       " 'hAST%_avg10',\n",
       " 'hSTL%_avg10',\n",
       " 'hBLK%_avg10',\n",
       " 'hDRtg_avg10',\n",
       " 'gq1_avg10',\n",
       " 'gq2_avg10',\n",
       " 'gq3_avg10',\n",
       " 'gq4_avg10',\n",
       " 'gPace_avg10',\n",
       " 'geFG%_avg10',\n",
       " 'gTOV%_avg10',\n",
       " 'gORB%_avg10',\n",
       " 'gFT/FGA_avg10',\n",
       " 'gORtg_avg10',\n",
       " 'gFG_avg10',\n",
       " 'gFGA_avg10',\n",
       " 'gFG%_avg10',\n",
       " 'g3P_avg10',\n",
       " 'g3PA_avg10',\n",
       " 'g3P%_avg10',\n",
       " 'gFT_avg10',\n",
       " 'gFTA_avg10',\n",
       " 'gFT%_avg10',\n",
       " 'gORB_avg10',\n",
       " 'gDRB_avg10',\n",
       " 'gTRB_avg10',\n",
       " 'gAST_avg10',\n",
       " 'gSTL_avg10',\n",
       " 'gBLK_avg10',\n",
       " 'gTOV_avg10',\n",
       " 'gPF_avg10',\n",
       " 'gPTS_avg10',\n",
       " 'gTS%_avg10',\n",
       " 'g3PAR_avg10',\n",
       " 'gFTr_avg10',\n",
       " 'gDRB%_avg10',\n",
       " 'gTRB%_avg10',\n",
       " 'gAST%_avg10',\n",
       " 'gSTL%_avg10',\n",
       " 'gBLK%_avg10',\n",
       " 'gDRtg_avg10',\n",
       " 'q1_headsup10',\n",
       " 'q2_headsup10',\n",
       " 'q3_headsup10',\n",
       " 'q4_headsup10',\n",
       " 'Pace_headsup10',\n",
       " 'PF_headsup10',\n",
       " 'FGA_headsup10',\n",
       " 'DRtg_headsup10',\n",
       " 'ORtg_headsup10',\n",
       " 'STL%_headsup10',\n",
       " 'TOV%_headsup10',\n",
       " 'ORB%_headsup10',\n",
       " 'DRB%_headsup10',\n",
       " 'TRB%_headsup10',\n",
       " 'BLK%_headsup10',\n",
       " 'HostName_Atlanta Hawks',\n",
       " 'HostName_Boston Celtics',\n",
       " 'HostName_Brooklyn Nets',\n",
       " 'HostName_Charlotte Hornets',\n",
       " 'HostName_Chicago Bulls',\n",
       " 'HostName_Cleveland Cavaliers',\n",
       " 'HostName_Dallas Mavericks',\n",
       " 'HostName_Denver Nuggets',\n",
       " 'HostName_Detroit Pistons',\n",
       " 'HostName_Golden State Warriors',\n",
       " 'HostName_Houston Rockets',\n",
       " 'HostName_Indiana Pacers',\n",
       " 'HostName_Los Angeles Clippers',\n",
       " 'HostName_Los Angeles Lakers',\n",
       " 'HostName_Memphis Grizzlies',\n",
       " 'HostName_Miami Heat',\n",
       " 'HostName_Milwaukee Bucks',\n",
       " 'HostName_Minnesota Timberwolves',\n",
       " 'HostName_New Orleans Pelicans',\n",
       " 'HostName_New York Knicks',\n",
       " 'HostName_Oklahoma City Thunder',\n",
       " 'HostName_Orlando Magic',\n",
       " 'HostName_Philadelphia 76ers',\n",
       " 'HostName_Phoenix Suns',\n",
       " 'HostName_Portland Trail Blazers',\n",
       " 'HostName_Sacramento Kings',\n",
       " 'HostName_San Antonio Spurs',\n",
       " 'HostName_Toronto Raptors',\n",
       " 'HostName_Utah Jazz',\n",
       " 'HostName_Washington Wizards',\n",
       " 'GuestName_Atlanta Hawks',\n",
       " 'GuestName_Boston Celtics',\n",
       " 'GuestName_Brooklyn Nets',\n",
       " 'GuestName_Charlotte Hornets',\n",
       " 'GuestName_Chicago Bulls',\n",
       " 'GuestName_Cleveland Cavaliers',\n",
       " 'GuestName_Dallas Mavericks',\n",
       " 'GuestName_Denver Nuggets',\n",
       " 'GuestName_Detroit Pistons',\n",
       " 'GuestName_Golden State Warriors',\n",
       " 'GuestName_Houston Rockets',\n",
       " 'GuestName_Indiana Pacers',\n",
       " 'GuestName_Los Angeles Clippers',\n",
       " 'GuestName_Los Angeles Lakers',\n",
       " 'GuestName_Memphis Grizzlies',\n",
       " 'GuestName_Miami Heat',\n",
       " 'GuestName_Milwaukee Bucks',\n",
       " 'GuestName_Minnesota Timberwolves',\n",
       " 'GuestName_New Orleans Pelicans',\n",
       " 'GuestName_New York Knicks',\n",
       " 'GuestName_Oklahoma City Thunder',\n",
       " 'GuestName_Orlando Magic',\n",
       " 'GuestName_Philadelphia 76ers',\n",
       " 'GuestName_Phoenix Suns',\n",
       " 'GuestName_Portland Trail Blazers',\n",
       " 'GuestName_Sacramento Kings',\n",
       " 'GuestName_San Antonio Spurs',\n",
       " 'GuestName_Toronto Raptors',\n",
       " 'GuestName_Utah Jazz',\n",
       " 'GuestName_Washington Wizards',\n",
       " 'winner_Atlanta Hawks',\n",
       " 'winner_Boston Celtics',\n",
       " 'winner_Brooklyn Nets',\n",
       " 'winner_Charlotte Hornets',\n",
       " 'winner_Chicago Bulls',\n",
       " 'winner_Cleveland Cavaliers',\n",
       " 'winner_Dallas Mavericks',\n",
       " 'winner_Denver Nuggets',\n",
       " 'winner_Detroit Pistons',\n",
       " 'winner_Golden State Warriors',\n",
       " 'winner_Houston Rockets',\n",
       " 'winner_Indiana Pacers',\n",
       " 'winner_Los Angeles Clippers',\n",
       " 'winner_Los Angeles Lakers',\n",
       " 'winner_Memphis Grizzlies',\n",
       " 'winner_Miami Heat',\n",
       " 'winner_Milwaukee Bucks',\n",
       " 'winner_Minnesota Timberwolves',\n",
       " 'winner_New Orleans Pelicans',\n",
       " 'winner_New York Knicks',\n",
       " 'winner_Oklahoma City Thunder',\n",
       " 'winner_Orlando Magic',\n",
       " 'winner_Philadelphia 76ers',\n",
       " 'winner_Phoenix Suns',\n",
       " 'winner_Portland Trail Blazers',\n",
       " 'winner_Sacramento Kings',\n",
       " 'winner_San Antonio Spurs',\n",
       " 'winner_Toronto Raptors',\n",
       " 'winner_Utah Jazz',\n",
       " 'winner_Washington Wizards',\n",
       " 'loser_Atlanta Hawks',\n",
       " 'loser_Boston Celtics',\n",
       " 'loser_Brooklyn Nets',\n",
       " 'loser_Charlotte Hornets',\n",
       " 'loser_Chicago Bulls',\n",
       " 'loser_Cleveland Cavaliers',\n",
       " 'loser_Dallas Mavericks',\n",
       " 'loser_Denver Nuggets',\n",
       " 'loser_Detroit Pistons',\n",
       " 'loser_Golden State Warriors',\n",
       " 'loser_Houston Rockets',\n",
       " 'loser_Indiana Pacers',\n",
       " 'loser_Los Angeles Clippers',\n",
       " 'loser_Los Angeles Lakers',\n",
       " 'loser_Memphis Grizzlies',\n",
       " 'loser_Miami Heat',\n",
       " 'loser_Milwaukee Bucks',\n",
       " 'loser_Minnesota Timberwolves',\n",
       " 'loser_New Orleans Pelicans',\n",
       " 'loser_New York Knicks',\n",
       " 'loser_Oklahoma City Thunder',\n",
       " 'loser_Orlando Magic',\n",
       " 'loser_Philadelphia 76ers',\n",
       " 'loser_Phoenix Suns',\n",
       " 'loser_Portland Trail Blazers',\n",
       " 'loser_Sacramento Kings',\n",
       " 'loser_San Antonio Spurs',\n",
       " 'loser_Toronto Raptors',\n",
       " 'loser_Utah Jazz',\n",
       " 'loser_Washington Wizards']"
      ]
     },
     "execution_count": 1322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dbscan_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbscan_data = dbscan_data.iloc[:,:-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 229) (271,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4925373134328358"
      ]
     },
     "execution_count": 1324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(dbscan_data, mytarget, test_size=0.33)\n",
    "print X_train.shape, y_train.shape\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "preds = []\n",
    "preds = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 1326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAHcCAYAAAAeFogrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x8FLmNldWdBBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cbe4550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mytarget.bad_games.values, Kmean_result, c=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
